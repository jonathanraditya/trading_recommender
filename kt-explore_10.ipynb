{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2261654a-9ccd-482e-be09-06331e4743b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow --quiet\n",
    "# !pip install keras_tuner --quiet\n",
    "# !pip install tensorflow-io --quiet\n",
    "# # Google colab modules\n",
    "# from google.colab import drive\n",
    "import sys, importlib\n",
    "\n",
    "# # Mount drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "ROOT_PATH = './'\n",
    "# sys.path.append(ROOT_PATH)\n",
    "\n",
    "import coremlv2 as core\n",
    "core._init_ml()\n",
    "# core._init_models()\n",
    "# core.os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Reload coreml\n",
    "importlib.reload(core)\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a4f43b3-1d2f-4e5a-8088-7b96126c61f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs,  1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Limiting GPU memory growth\n",
    "gpus = core.tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            core.tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = core.tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs, \", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2ca21-7a16-450f-8657-7673863d934c",
   "metadata": {},
   "source": [
    "### model_323_kt - world stock data (small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d67d79-9ea9-4484-bcae-1799bc55a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kt_iter = '26'\n",
    "ticker_group = ['wsd']\n",
    "epochs = 20\n",
    "max_epochs = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a32cbc-d375-4e14-af8f-5757e742d9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 22\n",
      "Total constituents: 8\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 'small'\n",
    "shuffle_buffer_size = 1024\n",
    "generator = False\n",
    "\n",
    "train_inputs, train_labels = core.load_dataset_wsd_traintest(subset='training', dataset_size=dataset_size, ROOT_PATH='''H:\\#PROJECT\\idx''', db_ver='8', batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator)\n",
    "\n",
    "validation_inputs, validation_labels = core.load_dataset_wsd_traintest(subset='validation', dataset_size=dataset_size, ROOT_PATH='''H:\\#PROJECT\\idx''', db_ver='8', batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004c1936-69fa-4914-8420-58905446df1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 30m 10s]\n",
      "val_loss: 0.6954605579376221\n",
      "\n",
      "Best val_loss So Far: 0.6693868637084961\n",
      "Total elapsed time: 05h 08m 03s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(hypermodel=core.model_323_kt, objective='val_loss', max_epochs=max_epochs, hyperband_iterations=1, overwrite=True, directory=f'{ROOT_PATH}models/kt/v{kt_iter}/', project_name='_'.join(ticker_group))\n",
    "\n",
    "tuner.search(train_inputs, train_labels, validation_data=(validation_inputs, validation_labels), epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a6a52f-aadf-4071-98af-7dcbb62a415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 26m 20s]\n",
      "val_loss: 0.6987267732620239\n",
      "\n",
      "Best val_loss So Far: 0.6756389141082764\n",
      "Total elapsed time: 05h 46m 26s\n"
     ]
    }
   ],
   "source": [
    "kt_iter = '28'\n",
    "ticker_group = ['wsd']\n",
    "epochs = 20\n",
    "max_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "dataset_size = 'small'\n",
    "shuffle_buffer_size = 1024\n",
    "generator = False\n",
    "\n",
    "train_inputs, train_labels = core.load_dataset_wsd_traintest(subset='training', dataset_size=dataset_size, ROOT_PATH='''H:\\#PROJECT\\idx''', db_ver='8', batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator)\n",
    "\n",
    "validation_inputs, validation_labels = core.load_dataset_wsd_traintest(subset='validation', dataset_size=dataset_size, ROOT_PATH='''H:\\#PROJECT\\idx''', db_ver='8', batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator)\n",
    "\n",
    "tuner = kt.Hyperband(hypermodel=core.model_325_kt, objective='val_loss', max_epochs=max_epochs, hyperband_iterations=1, overwrite=True, directory=f'{ROOT_PATH}models/kt/v{kt_iter}/', project_name='_'.join(ticker_group))\n",
    "\n",
    "tuner.search(train_inputs, train_labels, validation_data=(validation_inputs, validation_labels), epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54de16-47b8-4b80-97f3-e24991a640ce",
   "metadata": {},
   "source": [
    "### 325/31 v8 full_new_wsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ef9ab-4438-4a90-8066-1187a3b9c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 12m 10s]\n",
      "val_loss: 0.6963037252426147\n",
      "\n",
      "Best val_loss So Far: 0.6912412643432617\n",
      "Total elapsed time: 02h 01m 34s\n",
      "\n",
      "Search: Running Trial #11\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "lr                |4.1844e-05        |2.4351e-05        \n",
      "c_filters         |48                |64                \n",
      "r_units           |112               |112               \n",
      "tuner/epochs      |3                 |3                 \n",
      "tuner/initial_e...|0                 |0                 \n",
      "tuner/bracket     |2                 |2                 \n",
      "tuner/round       |0                 |0                 \n",
      "\n",
      "Epoch 1/3\n",
      "5345/5345 [==============================] - 244s 44ms/step - loss: 0.6783 - accuracy: 0.5427 - val_loss: 0.6927 - val_accuracy: 0.5307\n",
      "Epoch 2/3\n",
      "5345/5345 [==============================] - 231s 43ms/step - loss: 0.6614 - accuracy: 0.5755 - val_loss: 0.6919 - val_accuracy: 0.5307\n",
      "Epoch 3/3\n",
      "1827/5345 [=========>....................] - ETA: 1:52 - loss: 0.6870 - accuracy: 0.5281"
     ]
    }
   ],
   "source": [
    "model_no = '325'\n",
    "kt_iter = '31'\n",
    "ticker_group = ['wsd']\n",
    "epochs = 20\n",
    "max_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "dataset_size = 'full_new_wsd'\n",
    "shuffle_buffer_size = 2048\n",
    "generator = False\n",
    "\n",
    "train_inputs, train_labels = core.load_dataset_wsd_traintest(subset='training', dataset_size=dataset_size, ROOT_PATH='''J:\\#PROJECT\\idx''', db_ver='8', batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "validation_inputs, validation_labels = core.load_dataset_wsd_traintest(subset='validation', dataset_size=dataset_size, ROOT_PATH='''J:\\#PROJECT\\idx''', db_ver='8', batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "tuner = kt.Hyperband(hypermodel=core.model_325_kt, objective='val_loss', max_epochs=max_epochs, hyperband_iterations=1, overwrite=True, directory=f'{ROOT_PATH}models/kt/v{kt_iter}/', project_name='_'.join(ticker_group))\n",
    "\n",
    "tuner.search(train_inputs, train_labels, validation_data=(validation_inputs, validation_labels), epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18f9c1-7ee5-4a7b-a10f-5481f1c8d6aa",
   "metadata": {},
   "source": [
    "### Run with revised generator\n",
    "- Use 326 as early benchmark model, with world portion variation to find the optimal point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e0e5c-65fe-42da-8b98-494875996454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 3386\n",
      "Total constituents: 422\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "lr                |0.0082852         |?                 \n",
      "r_units           |112               |?                 \n",
      "d_units_1         |64                |?                 \n",
      "d_units_2         |64                |?                 \n",
      "tuner/epochs      |2                 |?                 \n",
      "tuner/initial_e...|0                 |?                 \n",
      "tuner/bracket     |3                 |?                 \n",
      "tuner/round       |0                 |?                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RERUN WITH REVISED traintest slice code\n",
    "model_no = '326'\n",
    "constituent_limits = 0.05\n",
    "id_constituent = 1\n",
    "kt_iter = f'_model-{model_no}_wc-{constituent_limits}_ic-{id_constituent}'\n",
    "ticker_group = ['wsd']\n",
    "epochs = 40\n",
    "max_epochs = 40\n",
    "batch_size = 2048\n",
    "shuffle_buffer_size = 16\n",
    "generator = True\n",
    "\n",
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH='''J:\\#PROJECT\\idx''', db_ver='8', constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH='''J:\\#PROJECT\\idx''', db_ver='8', constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "tuner = kt.Hyperband(hypermodel=core.model_326_kt, objective='val_loss', max_epochs=max_epochs, hyperband_iterations=1, overwrite=True, directory=f'{ROOT_PATH}models/kt/v{kt_iter}/', project_name='_'.join(ticker_group))\n",
    "\n",
    "tuner.search(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ad132-e53f-4958-8814-4fbaec355482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf016f59-c198-40e0-9916-273d33192559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e813725-2aab-4c4b-9fda-983954df7e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
