{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cb36c6-f230-4132-902d-ccf67be974d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow --quiet\n",
    "# !pip install keras_tuner --quiet\n",
    "# !pip install tensorflow-io --quiet\n",
    "# # Google colab modules\n",
    "# from google.colab import drive\n",
    "import sys, importlib\n",
    "\n",
    "# # Mount drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "ROOT_PATH = './'\n",
    "# sys.path.append(ROOT_PATH)\n",
    "\n",
    "import coremlv2 as core\n",
    "core._init_ml()\n",
    "# core._init_models()\n",
    "core.os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "# Reload coreml\n",
    "importlib.reload(core)\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d6e01-173a-4743-aa38-29a7f23386d0",
   "metadata": {},
   "source": [
    "#### Use multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42c4049-f801-49f7-9b52-9facb5d87bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs,  10 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "memory_limit = 2816 # 2 + 4\n",
    "memory_limit = 2300 # 3 + 5\n",
    "memory_limit = 3500 # 2 + 3\n",
    "memory_limit = 1700 # 4 + 6\n",
    "memory_limit = 1850 # 4 + 6, display moved to titan X\n",
    "memory_limit = 1750 # 4 + 6, display moved to titan X, increase gpu free memory\n",
    "gpus = core.tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Create virtual GPUs\n",
    "    try:\n",
    "        core.tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit),\n",
    "             core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit),\n",
    "             core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit),\n",
    "             core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit)])\n",
    "        core.tf.config.set_logical_device_configuration(\n",
    "            gpus[1],\n",
    "            [core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit),\n",
    "             core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit),\n",
    "             core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit),\n",
    "             core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit),\n",
    "             core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit),\n",
    "             core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit)])\n",
    "        logical_gpus = core.tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs, \", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63a4f88-aebe-4133-b6b3-e7f23b75253c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs,  2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "memory_limit = 1750 # 6 vgpu\n",
    "memory_limit = 3500 # 3 vgpu\n",
    "memory_limit = 5250 # 2 vgpu\n",
    "# memory_limit = 3000 # 2 vgpu\n",
    "gpus = core.tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Create virtual GPUs\n",
    "    try:\n",
    "        core.tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit),\n",
    "             core.tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit)])\n",
    "        logical_gpus = core.tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs, \", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67890f9e-8189-46e9-882c-5611c1ee1962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs,  1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Limiting GPU memory growth\n",
    "gpus = core.tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            core.tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = core.tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs, \", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01755405-bd34-4439-a4d4-e9640afb5e48",
   "metadata": {},
   "source": [
    "### Manually retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8204ae29-c79c-48ff-9ee5-f7ccecb245f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '3'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.025\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.5\n",
    "epochs = 5\n",
    "iter_id = f'model-{model_no}-{version}_constituent_limits-{constituent_limits}_id_constituent-{id_constituent}_min_vid_constituents-{min_vid_constituents}_epochs-{epochs}'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "batch_size = 256\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bf182a-073d-400a-95ca-43b6aefa14f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 1149\n",
      "Total constituents: 422\n",
      "Epoch 1/5\n",
      "4879/4879 [==============================] - 1353s 276ms/step - loss: 0.6750 - accuracy: 0.5869 - val_loss: 0.6662 - val_accuracy: 0.5994\n",
      "Epoch 2/5\n",
      "4879/4879 [==============================] - 1445s 296ms/step - loss: 0.6591 - accuracy: 0.6071 - val_loss: 0.6657 - val_accuracy: 0.6018\n",
      "Epoch 3/5\n",
      "4879/4879 [==============================] - 1576s 323ms/step - loss: 0.6538 - accuracy: 0.6131 - val_loss: 0.6776 - val_accuracy: 0.5756\n",
      "Epoch 4/5\n",
      "4879/4879 [==============================] - 1465s 300ms/step - loss: 0.6478 - accuracy: 0.6190 - val_loss: 0.7006 - val_accuracy: 0.5678\n",
      "Epoch 5/5\n",
      "4879/4879 [==============================] - 1513s 310ms/step - loss: 0.6415 - accuracy: 0.6237 - val_loss: 0.7225 - val_accuracy: 0.5590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001A17D74E880> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001A17DFB6E50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "history.history['batch_size'] = batch_size\n",
    "history.history['shuffle_buffer_size'] = shuffle_buffer_size\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45329a8d-6e44-4b45-957e-c72bf1f7539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '3'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.025\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.5\n",
    "epochs = 10\n",
    "iter_id = f'model-{model_no}-{version}_constituent_limits-{constituent_limits}_id_constituent-{id_constituent}_min_vid_constituents-{min_vid_constituents}_epochs-{epochs}'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "batch_size = 4096\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97489aa9-d962-49f3-b05f-4cb94d481293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 1149\n",
      "Total constituents: 422\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "   Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 256, 1, 120, 4096, 256] \n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm_1/PartitionedCall]] [Op:__inference_train_function_431164]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JONATH~1\\AppData\\Local\\Temp/ipykernel_10492/2147333178.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Load model backbone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_switcher_preloaded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROOT_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'models/preloaded/{iter_id}/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:    Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 256, 1, 120, 4096, 256] \n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm_1/PartitionedCall]] [Op:__inference_train_function_431164]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "history.history['batch_size'] = batch_size\n",
    "history.history['shuffle_buffer_size'] = shuffle_buffer_size\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982d4e93-9d81-4c09-9f40-094990c12820",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '4'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.025\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.5\n",
    "epochs = 10\n",
    "batch_size = 1024\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf4f9a1-f655-4c3b-95d3-ce8c51031b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 1149\n",
      "Total constituents: 422\n",
      "Epoch 1/10\n",
      "1220/1220 [==============================] - 1437s 1s/step - loss: 0.6906 - accuracy: 0.5579 - val_loss: 0.6789 - val_accuracy: 0.5665\n",
      "Epoch 2/10\n",
      "1220/1220 [==============================] - 1392s 1s/step - loss: 0.6600 - accuracy: 0.6013 - val_loss: 0.6691 - val_accuracy: 0.5814\n",
      "Epoch 3/10\n",
      "1220/1220 [==============================] - 1359s 1s/step - loss: 0.6536 - accuracy: 0.6107 - val_loss: 0.6691 - val_accuracy: 0.5839\n",
      "Epoch 4/10\n",
      "1220/1220 [==============================] - 1348s 1s/step - loss: 0.6494 - accuracy: 0.6160 - val_loss: 0.6676 - val_accuracy: 0.5865\n",
      "Epoch 5/10\n",
      "1220/1220 [==============================] - 1352s 1s/step - loss: 0.6457 - accuracy: 0.6201 - val_loss: 0.6704 - val_accuracy: 0.5844\n",
      "Epoch 6/10\n",
      "1220/1220 [==============================] - 1356s 1s/step - loss: 0.6416 - accuracy: 0.6242 - val_loss: 0.6705 - val_accuracy: 0.5853\n",
      "Epoch 7/10\n",
      "1220/1220 [==============================] - 1393s 1s/step - loss: 0.6368 - accuracy: 0.6289 - val_loss: 0.6742 - val_accuracy: 0.5842\n",
      "Epoch 8/10\n",
      "1220/1220 [==============================] - 1436s 1s/step - loss: 0.6318 - accuracy: 0.6346 - val_loss: 0.6782 - val_accuracy: 0.5822\n",
      "Epoch 9/10\n",
      "1220/1220 [==============================] - 1415s 1s/step - loss: 0.6264 - accuracy: 0.6396 - val_loss: 0.6833 - val_accuracy: 0.5801\n",
      "Epoch 10/10\n",
      "1220/1220 [==============================] - 1399s 1s/step - loss: 0.6208 - accuracy: 0.6450 - val_loss: 0.6904 - val_accuracy: 0.5780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001F8957615B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001F896FC6DF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001F897235280> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8452e63a-2360-432e-946e-34ebf83ef2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '3'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.5\n",
    "epochs = 10\n",
    "batch_size = 1024\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c016e1-a23b-49d2-a7b9-e0458f7b0e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 422\n",
      "Total constituents: 422\n",
      "Epoch 1/10\n",
      "825/825 [==============================] - 690s 828ms/step - loss: 0.6952 - accuracy: 0.5652 - val_loss: 0.6669 - val_accuracy: 0.5835\n",
      "Epoch 2/10\n",
      "825/825 [==============================] - 677s 821ms/step - loss: 0.6607 - accuracy: 0.6000 - val_loss: 0.6629 - val_accuracy: 0.5888\n",
      "Epoch 3/10\n",
      "825/825 [==============================] - 741s 897ms/step - loss: 0.6521 - accuracy: 0.6110 - val_loss: 0.6581 - val_accuracy: 0.5940\n",
      "Epoch 4/10\n",
      "825/825 [==============================] - 689s 835ms/step - loss: 0.6466 - accuracy: 0.6176 - val_loss: 0.6574 - val_accuracy: 0.5957\n",
      "Epoch 5/10\n",
      "825/825 [==============================] - 734s 889ms/step - loss: 0.6418 - accuracy: 0.6229 - val_loss: 0.6600 - val_accuracy: 0.5956\n",
      "Epoch 6/10\n",
      "825/825 [==============================] - 728s 882ms/step - loss: 0.6371 - accuracy: 0.6274 - val_loss: 0.6620 - val_accuracy: 0.5934\n",
      "Epoch 7/10\n",
      "825/825 [==============================] - 721s 873ms/step - loss: 0.6324 - accuracy: 0.6325 - val_loss: 0.6646 - val_accuracy: 0.5917\n",
      "Epoch 8/10\n",
      "825/825 [==============================] - 716s 867ms/step - loss: 0.6277 - accuracy: 0.6367 - val_loss: 0.6695 - val_accuracy: 0.5898\n",
      "Epoch 9/10\n",
      "825/825 [==============================] - 711s 861ms/step - loss: 0.6227 - accuracy: 0.6420 - val_loss: 0.6733 - val_accuracy: 0.5892\n",
      "Epoch 10/10\n",
      "825/825 [==============================] - 708s 858ms/step - loss: 0.6175 - accuracy: 0.6470 - val_loss: 0.6797 - val_accuracy: 0.5853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D20B8151C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D21BB2DA00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97cae51-f010-4fde-bef2-eaee97ad9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '3'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.05\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.3\n",
    "epochs = 10\n",
    "batch_size = 512\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f5377f-3054-4bb2-83e8-ebea6812347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 2039\n",
      "Total constituents: 422\n",
      "Epoch 1/10\n",
      "3895/3895 [==============================] - 2167s 554ms/step - loss: 0.6732 - accuracy: 0.5884 - val_loss: 0.6601 - val_accuracy: 0.5985\n",
      "Epoch 2/10\n",
      "3895/3895 [==============================] - 2236s 574ms/step - loss: 0.6559 - accuracy: 0.6094 - val_loss: 0.6625 - val_accuracy: 0.6004\n",
      "Epoch 3/10\n",
      "3895/3895 [==============================] - 2189s 562ms/step - loss: 0.6512 - accuracy: 0.6143 - val_loss: 0.6663 - val_accuracy: 0.6001\n",
      "Epoch 4/10\n",
      "3895/3895 [==============================] - 2275s 584ms/step - loss: 0.6470 - accuracy: 0.6182 - val_loss: 0.6710 - val_accuracy: 0.6000\n",
      "Epoch 5/10\n",
      "3895/3895 [==============================] - 2222s 570ms/step - loss: 0.6427 - accuracy: 0.6219 - val_loss: 0.6783 - val_accuracy: 0.5884\n",
      "Epoch 6/10\n",
      "3895/3895 [==============================] - 2245s 576ms/step - loss: 0.6384 - accuracy: 0.6257 - val_loss: 0.6924 - val_accuracy: 0.5776\n",
      "Epoch 7/10\n",
      "3895/3895 [==============================] - 2298s 590ms/step - loss: 0.6341 - accuracy: 0.6299 - val_loss: 0.6991 - val_accuracy: 0.5770\n",
      "Epoch 8/10\n",
      "3895/3895 [==============================] - 2218s 569ms/step - loss: 0.6296 - accuracy: 0.6341 - val_loss: 0.7083 - val_accuracy: 0.5747\n",
      "Epoch 9/10\n",
      "3895/3895 [==============================] - 2232s 573ms/step - loss: 0.6249 - accuracy: 0.6385 - val_loss: 0.7265 - val_accuracy: 0.5728\n",
      "Epoch 10/10\n",
      "3895/3895 [==============================] - 2195s 563ms/step - loss: 0.6203 - accuracy: 0.6430 - val_loss: 0.7342 - val_accuracy: 0.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002970CC9B8E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002971DE65D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da732636-4cb0-4936-a9f7-48b7197eae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '3'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.025\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.6\n",
    "epochs = 10\n",
    "batch_size = 512\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_2'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7500bcc5-a1c0-4719-abf2-f32659c09a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 1416\n",
      "Total constituents: 422\n",
      "Epoch 1/10\n",
      "3521/3521 [==============================] - 1666s 471ms/step - loss: 0.6724 - accuracy: 0.5892 - val_loss: 0.6632 - val_accuracy: 0.5983\n",
      "Epoch 2/10\n",
      "3521/3521 [==============================] - 1681s 477ms/step - loss: 0.6542 - accuracy: 0.6113 - val_loss: 0.6621 - val_accuracy: 0.6031\n",
      "Epoch 3/10\n",
      "3521/3521 [==============================] - 1694s 481ms/step - loss: 0.6475 - accuracy: 0.6179 - val_loss: 0.6666 - val_accuracy: 0.6011\n",
      "Epoch 4/10\n",
      "3521/3521 [==============================] - 1726s 490ms/step - loss: 0.6411 - accuracy: 0.6241 - val_loss: 0.6742 - val_accuracy: 0.5880\n",
      "Epoch 5/10\n",
      "3521/3521 [==============================] - 1817s 516ms/step - loss: 0.6345 - accuracy: 0.6299 - val_loss: 0.6834 - val_accuracy: 0.5770\n",
      "Epoch 6/10\n",
      "3521/3521 [==============================] - 1795s 510ms/step - loss: 0.6279 - accuracy: 0.6360 - val_loss: 0.6980 - val_accuracy: 0.5693\n",
      "Epoch 7/10\n",
      "3521/3521 [==============================] - 1736s 493ms/step - loss: 0.6212 - accuracy: 0.6420 - val_loss: 0.7072 - val_accuracy: 0.5691\n",
      "Epoch 8/10\n",
      "3521/3521 [==============================] - 1667s 473ms/step - loss: 0.6142 - accuracy: 0.6486 - val_loss: 0.7237 - val_accuracy: 0.5594\n",
      "Epoch 9/10\n",
      "3521/3521 [==============================] - 1607s 456ms/step - loss: 0.6073 - accuracy: 0.6556 - val_loss: 0.7381 - val_accuracy: 0.5583\n",
      "Epoch 10/10\n",
      "3521/3521 [==============================] - 1589s 451ms/step - loss: 0.6006 - accuracy: 0.6617 - val_loss: 0.7579 - val_accuracy: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002372383AB80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000023785A88280> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f2551c-3af4-401e-89c0-4e7642b756f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '5'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.2\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.2\n",
    "epochs = 1\n",
    "batch_size = 512\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_2'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae673c-983b-465e-930c-d5f9878cb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 7216\n",
      "Total constituents: 422\n",
      "Epoch 1-1/1\n",
      "5149/5149 [==============================] - 1968s 381ms/step - loss: 0.7509 - accuracy: 0.5217 - val_loss: 0.6954 - val_accuracy: 0.5371\n",
      "Epoch 1-2/1\n",
      "5139/5139 [==============================] - 1991s 387ms/step - loss: 0.6865 - accuracy: 0.5517 - val_loss: 0.6803 - val_accuracy: 0.5647\n",
      "Epoch 1-3/1\n",
      "5114/5114 [==============================] - 1954s 382ms/step - loss: 0.6756 - accuracy: 0.5742 - val_loss: 0.6718 - val_accuracy: 0.5831\n",
      "Epoch 1-4/1\n",
      "5124/5124 [==============================] - 2281s 445ms/step - loss: 0.6686 - accuracy: 0.5872 - val_loss: 0.6673 - val_accuracy: 0.5924\n",
      "Epoch 1-5/1\n",
      "5072/5072 [==============================] - 2228s 439ms/step - loss: 0.6651 - accuracy: 0.5940 - val_loss: 0.6645 - val_accuracy: 0.5984\n",
      "Epoch 1-6/1\n",
      "   1096/Unknown - 444s 404ms/step - loss: 0.6629 - accuracy: 0.5985"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "if type(train_gen) == list:\n",
    "    for epoch in range(epochs):\n",
    "        for i, tg in enumerate(train_gen):\n",
    "            print(f'Epoch {epoch+1}-{i+1}/{epochs}')\n",
    "            history = model.fit(tg, validation_data=validation_gen, epochs=1, verbose=1)\n",
    "elif type(train_gen) != list:\n",
    "    history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49352a0a-b97a-499a-8aa6-14fef656fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '5'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.2\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.2\n",
    "epochs = 5\n",
    "batch_size = 1024\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_2'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d16b3d-b4b6-41a5-bda6-c1f2dfceea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 7216\n",
      "Total constituents: 422\n",
      "Epoch 1-1/5\n",
      "2596/2596 [==============================] - 2002s 769ms/step - loss: 0.7493 - accuracy: 0.5112 - val_loss: 0.7118 - val_accuracy: 0.5232\n",
      "Epoch 1-2/5\n",
      "2541/2541 [==============================] - 1974s 776ms/step - loss: 0.7009 - accuracy: 0.5300 - val_loss: 0.6927 - val_accuracy: 0.5418\n",
      "Epoch 1-3/5\n",
      "2569/2569 [==============================] - 1963s 764ms/step - loss: 0.6887 - accuracy: 0.5492 - val_loss: 0.6829 - val_accuracy: 0.5611\n",
      "Epoch 1-4/5\n",
      "2530/2530 [==============================] - 1933s 764ms/step - loss: 0.6804 - accuracy: 0.5651 - val_loss: 0.6771 - val_accuracy: 0.5728\n",
      "Epoch 1-5/5\n",
      "2543/2543 [==============================] - 1963s 772ms/step - loss: 0.6740 - accuracy: 0.5794 - val_loss: 0.6721 - val_accuracy: 0.5839\n",
      "Epoch 1-6/5\n",
      "2606/2606 [==============================] - 1970s 756ms/step - loss: 0.6694 - accuracy: 0.5879 - val_loss: 0.6688 - val_accuracy: 0.5901\n",
      "Epoch 1-7/5\n",
      "2592/2592 [==============================] - 1960s 756ms/step - loss: 0.6659 - accuracy: 0.5945 - val_loss: 0.6662 - val_accuracy: 0.5957\n",
      "Epoch 1-8/5\n",
      "525/525 [==============================] - 671s 1s/step - loss: 0.6658 - accuracy: 0.5958 - val_loss: 0.6656 - val_accuracy: 0.5971\n",
      "Epoch 2-1/5\n",
      "2596/2596 [==============================] - 1974s 760ms/step - loss: 0.6645 - accuracy: 0.5974 - val_loss: 0.6636 - val_accuracy: 0.6003\n",
      "Epoch 2-2/5\n",
      "2541/2541 [==============================] - 1939s 763ms/step - loss: 0.6631 - accuracy: 0.5994 - val_loss: 0.6626 - val_accuracy: 0.6019\n",
      "Epoch 2-3/5\n",
      "2569/2569 [==============================] - 1925s 749ms/step - loss: 0.6617 - accuracy: 0.6017 - val_loss: 0.6613 - val_accuracy: 0.6043\n",
      "Epoch 2-4/5\n",
      "2530/2530 [==============================] - 1897s 749ms/step - loss: 0.6610 - accuracy: 0.6016 - val_loss: 0.6610 - val_accuracy: 0.6047\n",
      "Epoch 2-5/5\n",
      "2543/2543 [==============================] - 1894s 745ms/step - loss: 0.6600 - accuracy: 0.6044 - val_loss: 0.6602 - val_accuracy: 0.6062\n",
      "Epoch 2-6/5\n",
      "2606/2606 [==============================] - 1974s 757ms/step - loss: 0.6593 - accuracy: 0.6057 - val_loss: 0.6598 - val_accuracy: 0.6068\n",
      "Epoch 2-7/5\n",
      "2592/2592 [==============================] - 1960s 756ms/step - loss: 0.6583 - accuracy: 0.6071 - val_loss: 0.6591 - val_accuracy: 0.6080\n",
      "Epoch 2-8/5\n",
      "525/525 [==============================] - 675s 1s/step - loss: 0.6590 - accuracy: 0.6075 - val_loss: 0.6588 - val_accuracy: 0.6085\n",
      "Epoch 3-1/5\n",
      "2596/2596 [==============================] - 1976s 761ms/step - loss: 0.6590 - accuracy: 0.6059 - val_loss: 0.6581 - val_accuracy: 0.6089\n",
      "Epoch 3-2/5\n",
      "2541/2541 [==============================] - 1952s 768ms/step - loss: 0.6586 - accuracy: 0.6062 - val_loss: 0.6580 - val_accuracy: 0.6094\n",
      "Epoch 3-3/5\n",
      "2569/2569 [==============================] - 1990s 774ms/step - loss: 0.6579 - accuracy: 0.6071 - val_loss: 0.6575 - val_accuracy: 0.6103\n",
      "Epoch 3-4/5\n",
      "2530/2530 [==============================] - 1927s 761ms/step - loss: 0.6581 - accuracy: 0.6060 - val_loss: 0.6575 - val_accuracy: 0.6098\n",
      "Epoch 3-5/5\n",
      "2543/2543 [==============================] - 1927s 758ms/step - loss: 0.6574 - accuracy: 0.6079 - val_loss: 0.6572 - val_accuracy: 0.6106\n",
      "Epoch 3-6/5\n",
      "2606/2606 [==============================] - 1970s 756ms/step - loss: 0.6570 - accuracy: 0.6088 - val_loss: 0.6570 - val_accuracy: 0.6107\n",
      "Epoch 3-7/5\n",
      "2592/2592 [==============================] - 1972s 760ms/step - loss: 0.6562 - accuracy: 0.6097 - val_loss: 0.6565 - val_accuracy: 0.6111\n",
      "Epoch 3-8/5\n",
      "525/525 [==============================] - 676s 1s/step - loss: 0.6568 - accuracy: 0.6101 - val_loss: 0.6563 - val_accuracy: 0.6113\n",
      "Epoch 4-1/5\n",
      "2596/2596 [==============================] - 1992s 767ms/step - loss: 0.6571 - accuracy: 0.6084 - val_loss: 0.6558 - val_accuracy: 0.6115\n",
      "Epoch 4-2/5\n",
      "2541/2541 [==============================] - 1964s 772ms/step - loss: 0.6570 - accuracy: 0.6082 - val_loss: 0.6558 - val_accuracy: 0.6119\n",
      "Epoch 4-3/5\n",
      "2569/2569 [==============================] - 1958s 762ms/step - loss: 0.6563 - accuracy: 0.6090 - val_loss: 0.6554 - val_accuracy: 0.6123\n",
      "Epoch 4-4/5\n",
      "2530/2530 [==============================] - 1925s 761ms/step - loss: 0.6568 - accuracy: 0.6076 - val_loss: 0.6555 - val_accuracy: 0.6121\n",
      "Epoch 4-5/5\n",
      "2543/2543 [==============================] - 1935s 760ms/step - loss: 0.6561 - accuracy: 0.6094 - val_loss: 0.6552 - val_accuracy: 0.6127\n",
      "Epoch 4-6/5\n",
      "2606/2606 [==============================] - 1964s 754ms/step - loss: 0.6558 - accuracy: 0.6102 - val_loss: 0.6550 - val_accuracy: 0.6125\n",
      "Epoch 4-7/5\n",
      "2592/2592 [==============================] - 1950s 752ms/step - loss: 0.6550 - accuracy: 0.6111 - val_loss: 0.6546 - val_accuracy: 0.6127\n",
      "Epoch 4-8/5\n",
      "525/525 [==============================] - 661s 1s/step - loss: 0.6555 - accuracy: 0.6114 - val_loss: 0.6544 - val_accuracy: 0.6132\n",
      "Epoch 5-1/5\n",
      "2596/2596 [==============================] - 1927s 742ms/step - loss: 0.6559 - accuracy: 0.6097 - val_loss: 0.6539 - val_accuracy: 0.6134\n",
      "Epoch 5-2/5\n",
      "2541/2541 [==============================] - 1861s 732ms/step - loss: 0.6560 - accuracy: 0.6093 - val_loss: 0.6539 - val_accuracy: 0.6136\n",
      "Epoch 5-3/5\n",
      "2569/2569 [==============================] - 1876s 730ms/step - loss: 0.6553 - accuracy: 0.6099 - val_loss: 0.6536 - val_accuracy: 0.6136\n",
      "Epoch 5-4/5\n",
      "2530/2530 [==============================] - 1857s 734ms/step - loss: 0.6560 - accuracy: 0.6083 - val_loss: 0.6538 - val_accuracy: 0.6135\n",
      "Epoch 5-5/5\n",
      "2543/2543 [==============================] - 1858s 731ms/step - loss: 0.6552 - accuracy: 0.6102 - val_loss: 0.6535 - val_accuracy: 0.6142\n",
      "Epoch 5-6/5\n",
      "2606/2606 [==============================] - 1896s 727ms/step - loss: 0.6550 - accuracy: 0.6109 - val_loss: 0.6533 - val_accuracy: 0.6139\n",
      "Epoch 5-7/5\n",
      "2592/2592 [==============================] - 1890s 729ms/step - loss: 0.6541 - accuracy: 0.6120 - val_loss: 0.6529 - val_accuracy: 0.6140\n",
      "Epoch 5-8/5\n",
      "525/525 [==============================] - 651s 1s/step - loss: 0.6545 - accuracy: 0.6121 - val_loss: 0.6528 - val_accuracy: 0.6144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000264E2976760> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000265E6E117C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "if type(train_gen) == list:\n",
    "    for epoch in range(epochs):\n",
    "        for i, tg in enumerate(train_gen):\n",
    "            print(f'Epoch {epoch+1}-{i+1}/{epochs}')\n",
    "            history = model.fit(tg, validation_data=validation_gen, epochs=1, verbose=1)\n",
    "elif type(train_gen) != list:\n",
    "    history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb1a7ef-3d95-40a9-9bfb-6c0236874f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '4'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.5\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.1\n",
    "epochs = 10\n",
    "batch_size = 256\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_2'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3607e7-faf3-44ec-9ff2-351760294d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 16419\n",
      "Total constituents: 422\n",
      "Epoch 1-1/10\n",
      "10047/10047 [==============================] - 3721s 369ms/step - loss: 0.6654 - accuracy: 0.5976 - val_loss: 0.6655 - val_accuracy: 0.5941\n",
      "Epoch 1-2/10\n",
      "10121/10121 [==============================] - 3557s 351ms/step - loss: 0.6550 - accuracy: 0.6108 - val_loss: 0.6660 - val_accuracy: 0.5963\n",
      "Epoch 1-3/10\n",
      "9893/9893 [==============================] - 3348s 338ms/step - loss: 0.6473 - accuracy: 0.6204 - val_loss: 0.6920 - val_accuracy: 0.5760\n",
      "Epoch 1-4/10\n",
      "10334/10334 [==============================] - 3471s 336ms/step - loss: 0.6384 - accuracy: 0.6287 - val_loss: 0.7397 - val_accuracy: 0.5681\n",
      "Epoch 1-5/10\n",
      "   1899/Unknown - 566s 298ms/step - loss: 0.6314 - accuracy: 0.6360"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "if type(train_gen) == list:\n",
    "    for epoch in range(epochs):\n",
    "        for i, tg in enumerate(train_gen):\n",
    "            print(f'Epoch {epoch+1}-{i+1}/{epochs}')\n",
    "            history = model.fit(tg, validation_data=validation_gen, epochs=1, verbose=1)\n",
    "elif type(train_gen) != list:\n",
    "    history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59d9178-493e-4b74-8e38-429e3a7c5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '3'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.15\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.2\n",
    "epochs = 10\n",
    "batch_size = 2048\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_2'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36861dcf-88be-4283-b71e-3f9a8bb65a09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 5428\n",
      "Total constituents: 422\n",
      "Epoch 1-1/10\n",
      "1273/1273 [==============================] - 2120s 2s/step - loss: 0.6760 - accuracy: 0.5828 - val_loss: 0.6578 - val_accuracy: 0.6023\n",
      "Epoch 1-2/10\n",
      "1266/1266 [==============================] - 2117s 2s/step - loss: 0.6572 - accuracy: 0.6042 - val_loss: 0.6532 - val_accuracy: 0.6097\n",
      "Epoch 1-3/10\n",
      "1309/1309 [==============================] - 2174s 2s/step - loss: 0.6550 - accuracy: 0.6077 - val_loss: 0.6492 - val_accuracy: 0.6146\n",
      "Epoch 1-4/10\n",
      "1281/1281 [==============================] - 2149s 2s/step - loss: 0.6538 - accuracy: 0.6094 - val_loss: 0.6499 - val_accuracy: 0.6174\n",
      "Epoch 1-5/10\n",
      "1274/1274 [==============================] - 2139s 2s/step - loss: 0.6525 - accuracy: 0.6103 - val_loss: 0.6511 - val_accuracy: 0.6158\n",
      "Epoch 1-6/10\n",
      "572/572 [==============================] - 1087s 2s/step - loss: 0.6523 - accuracy: 0.6104 - val_loss: 0.6483 - val_accuracy: 0.6161\n",
      "Epoch 2-1/10\n",
      "1273/1273 [==============================] - 2088s 2s/step - loss: 0.6528 - accuracy: 0.6097 - val_loss: 0.6512 - val_accuracy: 0.6138\n",
      "Epoch 2-2/10\n",
      "1266/1266 [==============================] - 2095s 2s/step - loss: 0.6508 - accuracy: 0.6120 - val_loss: 0.6471 - val_accuracy: 0.6193\n",
      "Epoch 2-3/10\n",
      "1309/1309 [==============================] - 2100s 2s/step - loss: 0.6505 - accuracy: 0.6127 - val_loss: 0.6441 - val_accuracy: 0.6192\n",
      "Epoch 2-4/10\n",
      "1281/1281 [==============================] - 2043s 2s/step - loss: 0.6500 - accuracy: 0.6132 - val_loss: 0.6466 - val_accuracy: 0.6210\n",
      "Epoch 2-5/10\n",
      "1274/1274 [==============================] - 2041s 2s/step - loss: 0.6490 - accuracy: 0.6141 - val_loss: 0.6460 - val_accuracy: 0.6192\n",
      "Epoch 2-6/10\n",
      "572/572 [==============================] - 1062s 2s/step - loss: 0.6498 - accuracy: 0.6124 - val_loss: 0.6488 - val_accuracy: 0.6193\n",
      "Epoch 3-1/10\n",
      "1273/1273 [==============================] - 2018s 2s/step - loss: 0.6501 - accuracy: 0.6121 - val_loss: 0.6490 - val_accuracy: 0.6174\n",
      "Epoch 3-2/10\n",
      "1266/1266 [==============================] - 2033s 2s/step - loss: 0.6479 - accuracy: 0.6148 - val_loss: 0.6483 - val_accuracy: 0.6208\n",
      "Epoch 3-3/10\n",
      "1309/1309 [==============================] - 2071s 2s/step - loss: 0.6479 - accuracy: 0.6148 - val_loss: 0.6402 - val_accuracy: 0.6211\n",
      "Epoch 3-4/10\n",
      "1281/1281 [==============================] - 2035s 2s/step - loss: 0.6477 - accuracy: 0.6149 - val_loss: 0.6413 - val_accuracy: 0.6230\n",
      "Epoch 3-5/10\n",
      "1274/1274 [==============================] - 2038s 2s/step - loss: 0.6467 - accuracy: 0.6159 - val_loss: 0.6426 - val_accuracy: 0.6230\n",
      "Epoch 3-6/10\n",
      "572/572 [==============================] - 1032s 2s/step - loss: 0.6476 - accuracy: 0.6143 - val_loss: 0.6450 - val_accuracy: 0.6233\n",
      "Epoch 4-1/10\n",
      "1273/1273 [==============================] - 2017s 2s/step - loss: 0.6480 - accuracy: 0.6135 - val_loss: 0.6472 - val_accuracy: 0.6198\n",
      "Epoch 4-2/10\n",
      "1266/1266 [==============================] - 2020s 2s/step - loss: 0.6458 - accuracy: 0.6161 - val_loss: 0.6452 - val_accuracy: 0.6224\n",
      "Epoch 4-3/10\n",
      "1309/1309 [==============================] - 2066s 2s/step - loss: 0.6458 - accuracy: 0.6162 - val_loss: 0.6374 - val_accuracy: 0.6234\n",
      "Epoch 4-4/10\n",
      "1281/1281 [==============================] - 2033s 2s/step - loss: 0.6457 - accuracy: 0.6166 - val_loss: 0.6409 - val_accuracy: 0.6251\n",
      "Epoch 4-5/10\n",
      "1274/1274 [==============================] - 2030s 2s/step - loss: 0.6447 - accuracy: 0.6172 - val_loss: 0.6414 - val_accuracy: 0.6234\n",
      "Epoch 4-6/10\n",
      "572/572 [==============================] - 1027s 2s/step - loss: 0.6461 - accuracy: 0.6157 - val_loss: 0.6441 - val_accuracy: 0.6250\n",
      "Epoch 5-1/10\n",
      "1273/1273 [==============================] - 2015s 2s/step - loss: 0.6465 - accuracy: 0.6144 - val_loss: 0.6460 - val_accuracy: 0.6216\n",
      "Epoch 5-2/10\n",
      "1266/1266 [==============================] - 2025s 2s/step - loss: 0.6434 - accuracy: 0.6176 - val_loss: 0.6429 - val_accuracy: 0.6225\n",
      "Epoch 5-3/10\n",
      "1309/1309 [==============================] - 2102s 2s/step - loss: 0.6441 - accuracy: 0.6175 - val_loss: 0.6358 - val_accuracy: 0.6249\n",
      "Epoch 5-4/10\n",
      "1281/1281 [==============================] - 2047s 2s/step - loss: 0.6441 - accuracy: 0.6178 - val_loss: 0.6387 - val_accuracy: 0.6261\n",
      "Epoch 5-5/10\n",
      "1274/1274 [==============================] - 2102s 2s/step - loss: 0.6431 - accuracy: 0.6184 - val_loss: 0.6398 - val_accuracy: 0.6252\n",
      "Epoch 5-6/10\n",
      "572/572 [==============================] - 1076s 2s/step - loss: 0.6446 - accuracy: 0.6165 - val_loss: 0.6439 - val_accuracy: 0.6231\n",
      "Epoch 6-1/10\n",
      "1273/1273 [==============================] - 2083s 2s/step - loss: 0.6450 - accuracy: 0.6155 - val_loss: 0.6446 - val_accuracy: 0.6194\n",
      "Epoch 6-2/10\n",
      "1266/1266 [==============================] - 2137s 2s/step - loss: 0.6418 - accuracy: 0.6191 - val_loss: 0.6400 - val_accuracy: 0.6242\n",
      "Epoch 6-3/10\n",
      "1309/1309 [==============================] - 2156s 2s/step - loss: 0.6430 - accuracy: 0.6182 - val_loss: 0.6367 - val_accuracy: 0.6250\n",
      "Epoch 6-4/10\n",
      "1281/1281 [==============================] - 2091s 2s/step - loss: 0.6431 - accuracy: 0.6187 - val_loss: 0.6431 - val_accuracy: 0.6271\n",
      "Epoch 6-5/10\n",
      "1274/1274 [==============================] - 2074s 2s/step - loss: 0.6421 - accuracy: 0.6194 - val_loss: 0.6419 - val_accuracy: 0.6243\n",
      "Epoch 6-6/10\n",
      "572/572 [==============================] - 1053s 2s/step - loss: 0.6436 - accuracy: 0.6174 - val_loss: 0.6501 - val_accuracy: 0.6124\n",
      "Epoch 7-1/10\n",
      "1273/1273 [==============================] - 2024s 2s/step - loss: 0.6441 - accuracy: 0.6163 - val_loss: 0.6441 - val_accuracy: 0.6227\n",
      "Epoch 7-2/10\n",
      "1266/1266 [==============================] - 2043s 2s/step - loss: 0.6404 - accuracy: 0.6202 - val_loss: 0.6377 - val_accuracy: 0.6253\n",
      "Epoch 7-3/10\n",
      "1309/1309 [==============================] - 2012s 2s/step - loss: 0.6419 - accuracy: 0.6192 - val_loss: 0.6362 - val_accuracy: 0.6244\n",
      "Epoch 7-4/10\n",
      "1281/1281 [==============================] - 1972s 2s/step - loss: 0.6413 - accuracy: 0.6199 - val_loss: 0.6445 - val_accuracy: 0.6191\n",
      "Epoch 7-5/10\n",
      "1274/1274 [==============================] - 1982s 2s/step - loss: 0.6408 - accuracy: 0.6202 - val_loss: 0.6406 - val_accuracy: 0.6258\n",
      "Epoch 7-6/10\n",
      "572/572 [==============================] - 1001s 2s/step - loss: 0.6426 - accuracy: 0.6180 - val_loss: 0.6524 - val_accuracy: 0.6090\n",
      "Epoch 8-1/10\n",
      "1273/1273 [==============================] - 1958s 2s/step - loss: 0.6430 - accuracy: 0.6170 - val_loss: 0.6449 - val_accuracy: 0.6211\n",
      "Epoch 8-2/10\n",
      "1266/1266 [==============================] - 2005s 2s/step - loss: 0.6392 - accuracy: 0.6211 - val_loss: 0.6386 - val_accuracy: 0.6253\n",
      "Epoch 8-3/10\n",
      "1309/1309 [==============================] - 2033s 2s/step - loss: 0.6409 - accuracy: 0.6200 - val_loss: 0.6343 - val_accuracy: 0.6275\n",
      "Epoch 8-4/10\n",
      "1281/1281 [==============================] - 1997s 2s/step - loss: 0.6402 - accuracy: 0.6209 - val_loss: 0.6467 - val_accuracy: 0.6177\n",
      "Epoch 8-5/10\n",
      "1274/1274 [==============================] - 2143s 2s/step - loss: 0.6400 - accuracy: 0.6209 - val_loss: 0.6457 - val_accuracy: 0.6159\n",
      "Epoch 8-6/10\n",
      "572/572 [==============================] - 1027s 2s/step - loss: 0.6419 - accuracy: 0.6186 - val_loss: 0.6596 - val_accuracy: 0.6044\n",
      "Epoch 9-1/10\n",
      "1273/1273 [==============================] - 1963s 2s/step - loss: 0.6420 - accuracy: 0.6180 - val_loss: 0.6511 - val_accuracy: 0.6090\n",
      "Epoch 9-2/10\n",
      "1266/1266 [==============================] - 1969s 2s/step - loss: 0.6382 - accuracy: 0.6220 - val_loss: 0.6385 - val_accuracy: 0.6254\n",
      "Epoch 9-3/10\n",
      "1309/1309 [==============================] - 2008s 2s/step - loss: 0.6400 - accuracy: 0.6209 - val_loss: 0.6350 - val_accuracy: 0.6272\n",
      "Epoch 9-4/10\n",
      "1281/1281 [==============================] - 1974s 2s/step - loss: 0.6390 - accuracy: 0.6216 - val_loss: 0.6561 - val_accuracy: 0.6094\n",
      "Epoch 9-5/10\n",
      "1274/1274 [==============================] - 2217s 2s/step - loss: 0.6389 - accuracy: 0.6219 - val_loss: 0.6403 - val_accuracy: 0.6238\n",
      "Epoch 9-6/10\n",
      "572/572 [==============================] - 1194s 2s/step - loss: 0.6409 - accuracy: 0.6193 - val_loss: 0.6623 - val_accuracy: 0.6047\n",
      "Epoch 10-1/10\n",
      "1273/1273 [==============================] - 2322s 2s/step - loss: 0.6411 - accuracy: 0.6189 - val_loss: 0.6586 - val_accuracy: 0.6050\n",
      "Epoch 10-2/10\n",
      "1266/1266 [==============================] - 2318s 2s/step - loss: 0.6371 - accuracy: 0.6228 - val_loss: 0.6411 - val_accuracy: 0.6246\n",
      "Epoch 10-3/10\n",
      "1309/1309 [==============================] - 2313s 2s/step - loss: 0.6390 - accuracy: 0.6216 - val_loss: 0.6377 - val_accuracy: 0.6249\n",
      "Epoch 10-4/10\n",
      "1281/1281 [==============================] - 1977s 2s/step - loss: 0.6381 - accuracy: 0.6226 - val_loss: 0.6516 - val_accuracy: 0.6171\n",
      "Epoch 10-5/10\n",
      "1274/1274 [==============================] - 1979s 2s/step - loss: 0.6380 - accuracy: 0.6229 - val_loss: 0.6453 - val_accuracy: 0.6173\n",
      "Epoch 10-6/10\n",
      "572/572 [==============================] - 1006s 2s/step - loss: 0.6398 - accuracy: 0.6201 - val_loss: 0.6712 - val_accuracy: 0.6030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018A10DA12B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018B22799AF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "if type(train_gen) == list:\n",
    "    for epoch in range(epochs):\n",
    "        for i, tg in enumerate(train_gen):\n",
    "            print(f'Epoch {epoch+1}-{i+1}/{epochs}')\n",
    "            history = model.fit(tg, validation_data=validation_gen, epochs=1, verbose=1)\n",
    "elif type(train_gen) != list:\n",
    "    history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00f95a5-26ba-4580-8c90-5c6936615ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '3'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.5\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.4\n",
    "epochs = 5\n",
    "batch_size = 1024\n",
    "load_dataset_wsd_ver_switcher = {'1':['1','world data load from test slice'],\n",
    "                                 '2':['2','world data load from train slice'],}\n",
    "load_dataset_wsd_ver = '2'\n",
    "shuffle_buffer_size = 1\n",
    "generator=True\n",
    "\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='E:\\#PROJECT\\idx'\n",
    "db_ver = '8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d657fb1-cbfc-4c56-84fc-a2289c3c2767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_subepochs_progress(folder_list, search_condition):\n",
    "    '''Return search_results for iter_id \n",
    "    \n",
    "    with format below:\n",
    "    \n",
    "    iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_loaddatasetwsdver-{load_dataset_wsd_ver_switcher[load_dataset_wsd_ver][0]}_shufflebuffersize-{shuffle_buffer_size}_generator-{1 if generator else 0}'\n",
    "    \n",
    "    with last part is epochs-subepochs progress'''\n",
    "    search_results = {}\n",
    "    for fl in folder_list:\n",
    "        if core.re.search(search_condition, fl):\n",
    "            progress = fl.split('_')[-1]\n",
    "            progress_split = tuple(progress.split('-'))\n",
    "            epochs, sub_epochs = progress_split\n",
    "            epochs, sub_epochs = int(epochs), int(sub_epochs)\n",
    "            if epochs not in search_results:\n",
    "                search_results[epochs] = []\n",
    "            if sub_epochs not in search_results[epochs]:\n",
    "                search_results[epochs].append(sub_epochs)\n",
    "    return search_results\n",
    "\n",
    "# Resume from file, save every sub-epochs\n",
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92570771-6977-493f-acc5-4ff9626c6420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define suffix-file-name (as complete as possible, contains all required params to reproduce)\n",
    "# iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_loaddatasetwsdver-{load_dataset_wsd_ver_switcher[load_dataset_wsd_ver][0]}_shufflebuffersize-{shuffle_buffer_size}_generator-{1 if generator else 0}'\n",
    "iter_id = f'{model_no}-{version}_cl-{constituent_limits}_idc-{id_constituent}_mid-{min_vid_constituents}_ep-{epochs}_bz-{batch_size}_ldtv-{load_dataset_wsd_ver_switcher[load_dataset_wsd_ver][0]}_sbuffs-{shuffle_buffer_size}_gen-{1 if generator else 0}'\n",
    "\n",
    "# Search for eligibility in selected folder\n",
    "preloaded_folder = core.os.path.join(ROOT_PATH, 'models/preloaded')\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "folder_list = core.os.listdir(preloaded_folder)\n",
    "\n",
    "# split, select last entry, split again into epochs-subepochs -> dictionary entry\n",
    "search_results = epochs_subepochs_progress(folder_list, iter_id)\n",
    "\n",
    "# Load default model if current entries aren't exists.\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "\n",
    "if type(train_gen) == list:\n",
    "    for epoch in range(epochs):\n",
    "        for i, tg in enumerate(train_gen):\n",
    "            complete_iter_id = f'{iter_id}_{epoch}-{i}'\n",
    "            save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{complete_iter_id}')\n",
    "            # Check epochs:\n",
    "            # Check if current complete file name already in folder\n",
    "            # If true, load model from file, continue to next loop\n",
    "            if epoch in search_results:\n",
    "                if i in search_results[epoch]:\n",
    "                    print(f'Epoch {epoch}-{i}/{epochs-1}: load existing model and continue...')\n",
    "                    model = core.tf.keras.models.load_model(f'{save_path}/model')\n",
    "                    \n",
    "                    # The loops are continued until the condition is false -> training begin using \n",
    "                    # last model in progress\n",
    "                    continue\n",
    "                elif i not in search_results[epoch]:\n",
    "                    print(f'Epoch {epoch}-{i}/{epochs-1}: processing...')\n",
    "            elif epoch not in search_results:\n",
    "                print(f'Epoch {epoch}-{i}/{epochs-1}: processing...')\n",
    "            \n",
    "            # Start retrain model if latest progress has been loaded.\n",
    "            history = model.fit(tg, validation_data=validation_gen, epochs=1, verbose=1)\n",
    "            \n",
    "            # save model after training, only and only if the model is retrained\n",
    "            model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "            model.save(f'{save_path}/model')\n",
    "            \n",
    "            # Save history.json if the model is retrained\n",
    "            with open(f'{save_path}/history.json', 'w') as f:\n",
    "                core.json.dump(history.history, f)\n",
    "                \n",
    "            # The model not reloaded from file if the model is retrained\n",
    "elif type(train_gen) != list:\n",
    "    history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "    with open(f'{save_path}/history.json', 'w') as f:\n",
    "        core.json.dump(history.history, f)\n",
    "        \n",
    "# Finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a15890-50b0-43de-aa3f-45fd18332e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '9'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.35\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.8\n",
    "epochs = 40\n",
    "batch_size = 2048\n",
    "load_dataset_wsd_ver_switcher = {'1':['1','world data load from test slice'],\n",
    "                                 '2':['2','world data load from train slice'],\n",
    "                                 '3':['3','validation data from test set'],}\n",
    "load_dataset_wsd_ver = '3'\n",
    "shuffle_buffer_size = 1\n",
    "generator = True\n",
    "hotstart = True\n",
    "# hotstart_from = '327-7_cl-0.005_idc-1_mid-0.3_ep-40_bz-1792_ldtv-3_sbuffs-1_gen-1_3-0'\n",
    "hotstart_from = '327-9_cl-0.001_idc-0.25_mid-0.9_ep-40_bz-512_ldtv-3_sbuffs-1_gen-1_15-0' # 0.6690 / 0.5891\n",
    "hotstart_from = '327-9_cl-0.005_idc-1_mid-0.9_ep-40_bz-2048_ldtv-3_sbuffs-1_gen-1_28-0' # 0.6459 / 0.6173\n",
    "hotstart_from = '327-9_cl-0.1_idc-1_mid-0.9_ep-40_bz-2048_ldtv-3_sbuffs-1_gen-1_7-5' # 0.6371 / 0.6281\n",
    "hotstart_from = '327-9_cl-0.15_idc-1_mid-0.9_ep-40_bz-2048_ldtv-3_sbuffs-1_gen-1_7-1' # 0.6298 / 0.6349\n",
    "hotstart_from = '327-9_cl-0.2_idc-1_mid-0.9_ep-40_bz-2048_ldtv-3_sbuffs-1_gen-1_6-3' # 0.6232 / 0.6408\n",
    "hotstart_from = '327-9_cl-0.25_idc-1_mid-0.8_ep-40_bz-2048_ldtv-3_sbuffs-1_gen-1_3-5' # 0.6212 / 0.6433\n",
    "hotstart_from = '327-9_cl-0.3_idc-1_mid-0.8_ep-40_bz-2048_ldtv-3_sbuffs-1_gen-1_3-4' # 0.6185 / 0.6465\n",
    "\n",
    "# hotstart_from = '327-10_cl-0.001_idc-0.25_mid-0.8_ep-40_bz-512_ldtv-3_sbuffs-1_gen-1_10-0' # 0.6703 / 0.5885\n",
    "# hotstart_from = '327-10_cl-0.005_idc-1_mid-0.8_ep-40_bz-512_ldtv-3_sbuffs-1_gen-1_7-0' # 0.6574 / 0.6065\n",
    "# hotstart_from = '327-10_cl-0.1_idc-1_mid-0.5_ep-40_bz-512_ldtv-3_sbuffs-1_gen-1_1-4' # 0.6535 / 0.6123\n",
    "distributed = True\n",
    "\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='E:\\#PROJECT\\idx'\n",
    "db_ver = '8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b293ee5-1ed6-4ed9-a37e-3e2ad00aa0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 19079\n",
      "Total constituents: 422\n"
     ]
    }
   ],
   "source": [
    "def epochs_subepochs_progress(folder_list, search_condition):\n",
    "    '''Return search_results for iter_id \n",
    "    \n",
    "    with format below:\n",
    "    \n",
    "    iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_loaddatasetwsdver-{load_dataset_wsd_ver_switcher[load_dataset_wsd_ver][0]}_shufflebuffersize-{shuffle_buffer_size}_generator-{1 if generator else 0}'\n",
    "    \n",
    "    with last part is epochs-subepochs progress'''\n",
    "    search_results = {}\n",
    "    for fl in folder_list:\n",
    "        if core.re.search(search_condition, fl):\n",
    "            progress = fl.split('_')[-1]\n",
    "            progress_split = tuple(progress.split('-'))\n",
    "            epochs, sub_epochs = progress_split\n",
    "            epochs, sub_epochs = int(epochs), int(sub_epochs)\n",
    "            if epochs not in search_results:\n",
    "                search_results[epochs] = []\n",
    "            if sub_epochs not in search_results[epochs]:\n",
    "                search_results[epochs].append(sub_epochs)\n",
    "    return search_results\n",
    "\n",
    "# Resume from file, save every sub-epochs\n",
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c14aa0-d326-41eb-90f4-97bb64765f57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-0/39: processing...\n",
      "1208/1208 [==============================] - 1675s 1s/step - loss: 0.6362 - accuracy: 0.6263 - val_loss: 0.6184 - val_accuracy: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-1/39: processing...\n",
      "1133/1133 [==============================] - 1564s 1s/step - loss: 0.6390 - accuracy: 0.6232 - val_loss: 0.6176 - val_accuracy: 0.6467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-2/39: processing...\n",
      "1193/1193 [==============================] - 1631s 1s/step - loss: 0.6375 - accuracy: 0.6239 - val_loss: 0.6187 - val_accuracy: 0.6462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-3/39: processing...\n",
      "1140/1140 [==============================] - 1577s 1s/step - loss: 0.6367 - accuracy: 0.6253 - val_loss: 0.6182 - val_accuracy: 0.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-4/39: processing...\n",
      "1163/1163 [==============================] - 1602s 1s/step - loss: 0.6373 - accuracy: 0.6244 - val_loss: 0.6185 - val_accuracy: 0.6469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-5/39: processing...\n",
      "1124/1124 [==============================] - 1577s 1s/step - loss: 0.6389 - accuracy: 0.6240 - val_loss: 0.6180 - val_accuracy: 0.6470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-6/39: processing...\n",
      "1189/1189 [==============================] - 1662s 1s/step - loss: 0.6404 - accuracy: 0.6225 - val_loss: 0.6184 - val_accuracy: 0.6469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-7/39: processing...\n",
      "1161/1161 [==============================] - 1642s 1s/step - loss: 0.6402 - accuracy: 0.6215 - val_loss: 0.6188 - val_accuracy: 0.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-8/39: processing...\n",
      "1163/1163 [==============================] - 1648s 1s/step - loss: 0.6368 - accuracy: 0.6259 - val_loss: 0.6185 - val_accuracy: 0.6470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-9/39: processing...\n",
      "1151/1151 [==============================] - 1636s 1s/step - loss: 0.6364 - accuracy: 0.6261 - val_loss: 0.6183 - val_accuracy: 0.6464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-10/39: processing...\n",
      "1154/1154 [==============================] - 1878s 2s/step - loss: 0.6378 - accuracy: 0.6243 - val_loss: 0.6187 - val_accuracy: 0.6464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-11/39: processing...\n",
      "1137/1137 [==============================] - 2332s 2s/step - loss: 0.6386 - accuracy: 0.6240 - val_loss: 0.6182 - val_accuracy: 0.6469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-12/39: processing...\n",
      "1173/1173 [==============================] - 1733s 1s/step - loss: 0.6384 - accuracy: 0.6241 - val_loss: 0.6179 - val_accuracy: 0.6472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-13/39: processing...\n",
      "1145/1145 [==============================] - 1721s 2s/step - loss: 0.6395 - accuracy: 0.6227 - val_loss: 0.6182 - val_accuracy: 0.6466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE62896250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A05E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628A8400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628AE220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628BAE20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002CE628C5C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0-14/39: processing...\n",
      "    173/Unknown - 255s 1s/step - loss: 0.6345 - accuracy: 0.6279"
     ]
    }
   ],
   "source": [
    "# Define suffix-file-name (as complete as possible, contains all required params to reproduce)\n",
    "# iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_loaddatasetwsdver-{load_dataset_wsd_ver_switcher[load_dataset_wsd_ver][0]}_shufflebuffersize-{shuffle_buffer_size}_generator-{1 if generator else 0}'\n",
    "iter_id = f'{model_no}-{version}_cl-{constituent_limits}_idc-{id_constituent}_mid-{min_vid_constituents}_ep-{epochs}_bz-{batch_size}_ldtv-{load_dataset_wsd_ver_switcher[load_dataset_wsd_ver][0]}_sbuffs-{shuffle_buffer_size}_gen-{1 if generator else 0}'\n",
    "\n",
    "# Search for eligibility in selected folder\n",
    "preloaded_folder = core.os.path.join(ROOT_PATH, 'models/preloaded')\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "folder_list = core.os.listdir(preloaded_folder)\n",
    "\n",
    "# split, select last entry, split again into epochs-subepochs -> dictionary entry\n",
    "search_results = epochs_subepochs_progress(folder_list, iter_id)\n",
    "\n",
    "if distributed:\n",
    "    core.tf.debugging.set_log_device_placement(True)\n",
    "    gpus = core.tf.config.list_logical_devices('GPU')\n",
    "    strategy = core.tf.distribute.MirroredStrategy(gpus)\n",
    "    with strategy.scope():\n",
    "        # Load default model if current entries aren't exists.\n",
    "        # Load model backbone\n",
    "        model = core.model_switcher_preloaded(model_no, version=version)\n",
    "        \n",
    "        if hotstart:\n",
    "            hotstart_save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{hotstart_from}')\n",
    "            model = core.tf.keras.models.load_model(f'{hotstart_save_path}/model')\n",
    "\n",
    "        if type(train_gen) == list:\n",
    "            for epoch in range(epochs):\n",
    "                for i, tg in enumerate(train_gen):\n",
    "                    complete_iter_id = f'{iter_id}_{epoch}-{i}'\n",
    "                    save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{complete_iter_id}')\n",
    "                    # Check epochs:\n",
    "                    # Check if current complete file name already in folder\n",
    "                    # If true, load model from file, continue to next loop\n",
    "                    if epoch in search_results:\n",
    "                        if i in search_results[epoch]:\n",
    "                            print(f'Epoch {epoch}-{i}/{epochs-1}: load existing model and continue...')\n",
    "                            model = core.tf.keras.models.load_model(f'{save_path}/model')\n",
    "\n",
    "                            # The loops are continued until the condition is false -> training begin using \n",
    "                            # last model in progress\n",
    "                            continue\n",
    "                        elif i not in search_results[epoch]:\n",
    "                            print(f'Epoch {epoch}-{i}/{epochs-1}: processing...')\n",
    "                    elif epoch not in search_results:\n",
    "                        print(f'Epoch {epoch}-{i}/{epochs-1}: processing...')\n",
    "\n",
    "                    # Start retrain model if latest progress has been loaded.\n",
    "                    history = model.fit(tg, validation_data=validation_gen, epochs=1, verbose=1)\n",
    "\n",
    "                    # save model after training, only and only if the model is retrained\n",
    "                    model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "                    model.save(f'{save_path}/model')\n",
    "\n",
    "                    # Save history.json if the model is retrained\n",
    "                    with open(f'{save_path}/history.json', 'w') as f:\n",
    "                        core.json.dump(history.history, f)\n",
    "\n",
    "                    # The model not reloaded from file if the model is retrained\n",
    "        elif type(train_gen) != list:\n",
    "            history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "            with open(f'{save_path}/history.json', 'w') as f:\n",
    "                core.json.dump(history.history, f)\n",
    "                \n",
    "elif not distributed:\n",
    "    print('Please modify some code to run in not distributed mode.')\n",
    "        \n",
    "# Finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aefaa9-40c0-456b-ae74-2fd0bd655886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a6a5a-4e94-4c8c-8208-bc82c9e37d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a01f2-c82e-4acd-89a8-1bdb0210016a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae727e80-2f6b-47c2-9288-99958d5052e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd045c1-497f-49e8-9817-e79af4d9981d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1530dd-863c-4784-9333-0506a99aef8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
