{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4c32fd-fbb8-4c1a-9954-94de9da39617",
   "metadata": {},
   "source": [
    "### Retrain with large epoch without generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54015204-b1ec-4c2c-87d0-d40d98d090bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow --quiet\n",
    "# !pip install keras_tuner --quiet\n",
    "# !pip install tensorflow-io --quiet\n",
    "# # Google colab modules\n",
    "# from google.colab import drive\n",
    "import sys, importlib\n",
    "\n",
    "# # Mount drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "ROOT_PATH = './'\n",
    "# sys.path.append(ROOT_PATH)\n",
    "\n",
    "import coremlv2 as core\n",
    "core._init_ml()\n",
    "# core._init_models()\n",
    "# core.os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Reload coreml\n",
    "importlib.reload(core)\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eea2dd2-804d-498f-b922-f6c6dffeb017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs,  1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Limiting GPU memory growth\n",
    "gpus = core.tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            core.tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = core.tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs, \", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8373daf3-ee52-4e61-8e7a-41ea6a822d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id='327'\n",
    "kt_iter='34'\n",
    "db_ver='8'\n",
    "ROOT_PATH = './'\n",
    "DB_ROOT_PATH = 'J:\\#PROJECT\\idx'\n",
    "dataset_size = 'full_new_wsd'\n",
    "batch_size = 64\n",
    "shuffle_buffer_size = 2048\n",
    "retrain_epochs = 200\n",
    "generator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e50e1-5e05-4685-9e5f-c0b33d954a1f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 423\n",
      "Total constituents: 423\n",
      "Load model from keras_tuner\n",
      "Epoch 1/200\n",
      "5416/5416 [==============================] - 162s 29ms/step - loss: 0.6535 - accuracy: 0.5880 - val_loss: 0.6378 - val_accuracy: 0.6075\n",
      "Epoch 2/200\n",
      "5416/5416 [==============================] - 152s 28ms/step - loss: 0.6409 - accuracy: 0.6073 - val_loss: 0.6322 - val_accuracy: 0.6167\n",
      "Epoch 3/200\n",
      "5416/5416 [==============================] - 154s 28ms/step - loss: 0.6369 - accuracy: 0.6114 - val_loss: 0.6342 - val_accuracy: 0.6139\n",
      "Epoch 4/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6349 - accuracy: 0.6131 - val_loss: 0.6278 - val_accuracy: 0.6193\n",
      "Epoch 5/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6322 - accuracy: 0.6160 - val_loss: 0.6252 - val_accuracy: 0.6245\n",
      "Epoch 6/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6295 - accuracy: 0.6189 - val_loss: 0.6225 - val_accuracy: 0.6260\n",
      "Epoch 7/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6271 - accuracy: 0.6213 - val_loss: 0.6208 - val_accuracy: 0.6274\n",
      "Epoch 8/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6243 - accuracy: 0.6236 - val_loss: 0.6185 - val_accuracy: 0.6307\n",
      "Epoch 9/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6220 - accuracy: 0.6257 - val_loss: 0.6143 - val_accuracy: 0.6338\n",
      "Epoch 10/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6187 - accuracy: 0.6303 - val_loss: 0.6121 - val_accuracy: 0.6356\n",
      "Epoch 11/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6161 - accuracy: 0.6308 - val_loss: 0.6083 - val_accuracy: 0.6419\n",
      "Epoch 12/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6129 - accuracy: 0.6341 - val_loss: 0.6039 - val_accuracy: 0.6448\n",
      "Epoch 13/200\n",
      "5416/5416 [==============================] - 145s 27ms/step - loss: 0.6097 - accuracy: 0.6386 - val_loss: 0.6005 - val_accuracy: 0.6490\n",
      "Epoch 14/200\n",
      "5416/5416 [==============================] - 146s 27ms/step - loss: 0.6061 - accuracy: 0.6423 - val_loss: 0.5922 - val_accuracy: 0.6555\n",
      "Epoch 15/200\n",
      "5416/5416 [==============================] - 147s 27ms/step - loss: 0.6021 - accuracy: 0.6461 - val_loss: 0.5881 - val_accuracy: 0.6585\n",
      "Epoch 16/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.5978 - accuracy: 0.6494 - val_loss: 0.5825 - val_accuracy: 0.6636\n",
      "Epoch 17/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.5931 - accuracy: 0.6540 - val_loss: 0.5788 - val_accuracy: 0.6686\n",
      "Epoch 18/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.5883 - accuracy: 0.6599 - val_loss: 0.5709 - val_accuracy: 0.6779\n",
      "Epoch 19/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.5833 - accuracy: 0.6640 - val_loss: 0.5644 - val_accuracy: 0.6822\n",
      "Epoch 20/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.5778 - accuracy: 0.6692 - val_loss: 0.5575 - val_accuracy: 0.6879\n",
      "Epoch 21/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.5720 - accuracy: 0.6751 - val_loss: 0.5517 - val_accuracy: 0.6925\n",
      "Epoch 22/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.5664 - accuracy: 0.6790 - val_loss: 0.5460 - val_accuracy: 0.6985\n",
      "Epoch 23/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.5605 - accuracy: 0.6833 - val_loss: 0.5361 - val_accuracy: 0.7063\n",
      "Epoch 24/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.5546 - accuracy: 0.6899 - val_loss: 0.5317 - val_accuracy: 0.7096\n",
      "Epoch 25/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.5490 - accuracy: 0.6938 - val_loss: 0.5224 - val_accuracy: 0.7173\n",
      "Epoch 26/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.5433 - accuracy: 0.6998 - val_loss: 0.5180 - val_accuracy: 0.7219\n",
      "Epoch 27/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.5372 - accuracy: 0.7040 - val_loss: 0.5084 - val_accuracy: 0.7264\n",
      "Epoch 28/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.5292 - accuracy: 0.7112 - val_loss: 0.5010 - val_accuracy: 0.7342\n",
      "Epoch 29/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.5234 - accuracy: 0.7155 - val_loss: 0.4913 - val_accuracy: 0.7417\n",
      "Epoch 30/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.5181 - accuracy: 0.7204 - val_loss: 0.4880 - val_accuracy: 0.7461\n",
      "Epoch 31/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.5119 - accuracy: 0.7254 - val_loss: 0.4776 - val_accuracy: 0.7521\n",
      "Epoch 32/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.5053 - accuracy: 0.7303 - val_loss: 0.4702 - val_accuracy: 0.7565\n",
      "Epoch 33/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4995 - accuracy: 0.7351 - val_loss: 0.4622 - val_accuracy: 0.7611\n",
      "Epoch 34/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4942 - accuracy: 0.7382 - val_loss: 0.4610 - val_accuracy: 0.7641\n",
      "Epoch 35/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4876 - accuracy: 0.7435 - val_loss: 0.4474 - val_accuracy: 0.7733\n",
      "Epoch 36/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.4812 - accuracy: 0.7487 - val_loss: 0.4400 - val_accuracy: 0.7777\n",
      "Epoch 37/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.4756 - accuracy: 0.7523 - val_loss: 0.4363 - val_accuracy: 0.7805\n",
      "Epoch 38/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.4714 - accuracy: 0.7543 - val_loss: 0.4306 - val_accuracy: 0.7855\n",
      "Epoch 39/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.4654 - accuracy: 0.7599 - val_loss: 0.4237 - val_accuracy: 0.7895\n",
      "Epoch 40/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4600 - accuracy: 0.7640 - val_loss: 0.4180 - val_accuracy: 0.7938\n",
      "Epoch 41/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4554 - accuracy: 0.7669 - val_loss: 0.4112 - val_accuracy: 0.7959\n",
      "Epoch 42/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4499 - accuracy: 0.7699 - val_loss: 0.4057 - val_accuracy: 0.8021\n",
      "Epoch 43/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4445 - accuracy: 0.7730 - val_loss: 0.4012 - val_accuracy: 0.8041\n",
      "Epoch 44/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4398 - accuracy: 0.7759 - val_loss: 0.3946 - val_accuracy: 0.8074\n",
      "Epoch 45/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4352 - accuracy: 0.7798 - val_loss: 0.3859 - val_accuracy: 0.8125\n",
      "Epoch 46/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4322 - accuracy: 0.7826 - val_loss: 0.3857 - val_accuracy: 0.8136\n",
      "Epoch 47/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4250 - accuracy: 0.7868 - val_loss: 0.3768 - val_accuracy: 0.8190\n",
      "Epoch 48/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4216 - accuracy: 0.7881 - val_loss: 0.3722 - val_accuracy: 0.8213\n",
      "Epoch 49/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4169 - accuracy: 0.7917 - val_loss: 0.3697 - val_accuracy: 0.8234\n",
      "Epoch 50/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.4120 - accuracy: 0.7954 - val_loss: 0.3603 - val_accuracy: 0.8282\n",
      "Epoch 51/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.4087 - accuracy: 0.7978 - val_loss: 0.3558 - val_accuracy: 0.8323\n",
      "Epoch 52/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.4036 - accuracy: 0.8008 - val_loss: 0.3505 - val_accuracy: 0.8355\n",
      "Epoch 53/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.4002 - accuracy: 0.8029 - val_loss: 0.3432 - val_accuracy: 0.8392\n",
      "Epoch 54/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3961 - accuracy: 0.8052 - val_loss: 0.3439 - val_accuracy: 0.8397\n",
      "Epoch 55/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3930 - accuracy: 0.8076 - val_loss: 0.3364 - val_accuracy: 0.8439\n",
      "Epoch 56/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3872 - accuracy: 0.8102 - val_loss: 0.3311 - val_accuracy: 0.8456\n",
      "Epoch 57/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3829 - accuracy: 0.8126 - val_loss: 0.3296 - val_accuracy: 0.8475\n",
      "Epoch 58/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3785 - accuracy: 0.8156 - val_loss: 0.3269 - val_accuracy: 0.8507\n",
      "Epoch 59/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3758 - accuracy: 0.8171 - val_loss: 0.3205 - val_accuracy: 0.8538\n",
      "Epoch 60/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3718 - accuracy: 0.8196 - val_loss: 0.3133 - val_accuracy: 0.8567\n",
      "Epoch 61/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3684 - accuracy: 0.8221 - val_loss: 0.3206 - val_accuracy: 0.8540\n",
      "Epoch 62/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3651 - accuracy: 0.8238 - val_loss: 0.3052 - val_accuracy: 0.8613\n",
      "Epoch 63/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3620 - accuracy: 0.8255 - val_loss: 0.3036 - val_accuracy: 0.8631\n",
      "Epoch 64/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3579 - accuracy: 0.8285 - val_loss: 0.3034 - val_accuracy: 0.8617\n",
      "Epoch 65/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3551 - accuracy: 0.8300 - val_loss: 0.3001 - val_accuracy: 0.8640\n",
      "Epoch 66/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3516 - accuracy: 0.8320 - val_loss: 0.2949 - val_accuracy: 0.8671\n",
      "Epoch 67/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3472 - accuracy: 0.8349 - val_loss: 0.2852 - val_accuracy: 0.8714\n",
      "Epoch 68/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3449 - accuracy: 0.8358 - val_loss: 0.2827 - val_accuracy: 0.8744\n",
      "Epoch 69/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3407 - accuracy: 0.8382 - val_loss: 0.2808 - val_accuracy: 0.8745\n",
      "Epoch 70/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3373 - accuracy: 0.8410 - val_loss: 0.2785 - val_accuracy: 0.8755\n",
      "Epoch 71/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.3351 - accuracy: 0.8414 - val_loss: 0.2713 - val_accuracy: 0.8795\n",
      "Epoch 72/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3318 - accuracy: 0.8431 - val_loss: 0.2699 - val_accuracy: 0.8811\n",
      "Epoch 73/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3286 - accuracy: 0.8451 - val_loss: 0.2677 - val_accuracy: 0.8819\n",
      "Epoch 74/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3260 - accuracy: 0.8461 - val_loss: 0.2615 - val_accuracy: 0.8846\n",
      "Epoch 75/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3234 - accuracy: 0.8473 - val_loss: 0.2607 - val_accuracy: 0.8869\n",
      "Epoch 76/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3195 - accuracy: 0.8499 - val_loss: 0.2534 - val_accuracy: 0.8885\n",
      "Epoch 77/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3152 - accuracy: 0.8532 - val_loss: 0.2537 - val_accuracy: 0.8889\n",
      "Epoch 78/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3124 - accuracy: 0.8538 - val_loss: 0.2529 - val_accuracy: 0.8894\n",
      "Epoch 79/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3098 - accuracy: 0.8552 - val_loss: 0.2456 - val_accuracy: 0.8937\n",
      "Epoch 80/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.3060 - accuracy: 0.8568 - val_loss: 0.2438 - val_accuracy: 0.8943\n",
      "Epoch 81/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.3045 - accuracy: 0.8592 - val_loss: 0.2418 - val_accuracy: 0.8955\n",
      "Epoch 82/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.3009 - accuracy: 0.8605 - val_loss: 0.2404 - val_accuracy: 0.8955\n",
      "Epoch 83/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.2986 - accuracy: 0.8620 - val_loss: 0.2328 - val_accuracy: 0.8991\n",
      "Epoch 84/200\n",
      "5416/5416 [==============================] - 149s 28ms/step - loss: 0.2957 - accuracy: 0.8636 - val_loss: 0.2344 - val_accuracy: 0.8980\n",
      "Epoch 85/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.2935 - accuracy: 0.8639 - val_loss: 0.2338 - val_accuracy: 0.9001\n",
      "Epoch 86/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.2907 - accuracy: 0.8660 - val_loss: 0.2303 - val_accuracy: 0.9016\n",
      "Epoch 87/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.2895 - accuracy: 0.8662 - val_loss: 0.2288 - val_accuracy: 0.9022\n",
      "Epoch 88/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.2852 - accuracy: 0.8700 - val_loss: 0.2208 - val_accuracy: 0.9060\n",
      "Epoch 89/200\n",
      "5416/5416 [==============================] - 150s 28ms/step - loss: 0.2836 - accuracy: 0.8706 - val_loss: 0.2184 - val_accuracy: 0.9067\n",
      "Epoch 90/200\n",
      "5416/5416 [==============================] - 151s 28ms/step - loss: 0.2824 - accuracy: 0.8710 - val_loss: 0.2196 - val_accuracy: 0.9070\n",
      "Epoch 91/200\n",
      "5416/5416 [==============================] - 155s 29ms/step - loss: 0.2806 - accuracy: 0.8718 - val_loss: 0.2178 - val_accuracy: 0.9080\n",
      "Epoch 92/200\n",
      "5416/5416 [==============================] - 151s 28ms/step - loss: 0.2761 - accuracy: 0.8748 - val_loss: 0.2112 - val_accuracy: 0.9120\n",
      "Epoch 93/200\n",
      "5416/5416 [==============================] - 153s 28ms/step - loss: 0.2748 - accuracy: 0.8746 - val_loss: 0.2066 - val_accuracy: 0.9135\n",
      "Epoch 94/200\n",
      "5416/5416 [==============================] - 152s 28ms/step - loss: 0.2727 - accuracy: 0.8762 - val_loss: 0.2057 - val_accuracy: 0.9148\n",
      "Epoch 95/200\n",
      "5416/5416 [==============================] - 152s 28ms/step - loss: 0.2701 - accuracy: 0.8773 - val_loss: 0.2023 - val_accuracy: 0.9166\n",
      "Epoch 96/200\n",
      "5416/5416 [==============================] - 155s 29ms/step - loss: 0.2673 - accuracy: 0.8789 - val_loss: 0.2008 - val_accuracy: 0.9162\n",
      "Epoch 97/200\n",
      "5416/5416 [==============================] - 158s 29ms/step - loss: 0.2637 - accuracy: 0.8806 - val_loss: 0.2008 - val_accuracy: 0.9164\n",
      "Epoch 98/200\n",
      "5416/5416 [==============================] - 152s 28ms/step - loss: 0.2637 - accuracy: 0.8808 - val_loss: 0.1966 - val_accuracy: 0.9173\n",
      "Epoch 99/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2604 - accuracy: 0.8820 - val_loss: 0.1971 - val_accuracy: 0.9199\n",
      "Epoch 100/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2601 - accuracy: 0.8821 - val_loss: 0.1914 - val_accuracy: 0.9216\n",
      "Epoch 101/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2575 - accuracy: 0.8840 - val_loss: 0.1889 - val_accuracy: 0.9222\n",
      "Epoch 102/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2556 - accuracy: 0.8861 - val_loss: 0.1894 - val_accuracy: 0.9209\n",
      "Epoch 103/200\n",
      "5416/5416 [==============================] - 156s 29ms/step - loss: 0.2526 - accuracy: 0.8863 - val_loss: 0.1879 - val_accuracy: 0.9210\n",
      "Epoch 104/200\n",
      "5416/5416 [==============================] - 153s 28ms/step - loss: 0.2514 - accuracy: 0.8874 - val_loss: 0.1840 - val_accuracy: 0.9242\n",
      "Epoch 105/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2488 - accuracy: 0.8888 - val_loss: 0.1823 - val_accuracy: 0.9240\n",
      "Epoch 106/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.2478 - accuracy: 0.8900 - val_loss: 0.1823 - val_accuracy: 0.9248\n",
      "Epoch 107/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2465 - accuracy: 0.8900 - val_loss: 0.1795 - val_accuracy: 0.9251\n",
      "Epoch 108/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2438 - accuracy: 0.8907 - val_loss: 0.1818 - val_accuracy: 0.9256\n",
      "Epoch 109/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2429 - accuracy: 0.8918 - val_loss: 0.1771 - val_accuracy: 0.9278\n",
      "Epoch 110/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.2404 - accuracy: 0.8937 - val_loss: 0.1785 - val_accuracy: 0.9283\n",
      "Epoch 111/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2395 - accuracy: 0.8937 - val_loss: 0.1748 - val_accuracy: 0.9288\n",
      "Epoch 112/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.2380 - accuracy: 0.8943 - val_loss: 0.1726 - val_accuracy: 0.9304\n",
      "Epoch 113/200\n",
      "5416/5416 [==============================] - 149s 27ms/step - loss: 0.2344 - accuracy: 0.8962 - val_loss: 0.1638 - val_accuracy: 0.9337\n",
      "Epoch 114/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2341 - accuracy: 0.8968 - val_loss: 0.1698 - val_accuracy: 0.9308\n",
      "Epoch 115/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2334 - accuracy: 0.8972 - val_loss: 0.1615 - val_accuracy: 0.9356\n",
      "Epoch 116/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2297 - accuracy: 0.8987 - val_loss: 0.1641 - val_accuracy: 0.9341\n",
      "Epoch 117/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2286 - accuracy: 0.9001 - val_loss: 0.1596 - val_accuracy: 0.9353\n",
      "Epoch 118/200\n",
      "5416/5416 [==============================] - 148s 27ms/step - loss: 0.2265 - accuracy: 0.9001 - val_loss: 0.1603 - val_accuracy: 0.9358\n",
      "Epoch 119/200\n",
      "5416/5416 [==============================] - 153s 28ms/step - loss: 0.2252 - accuracy: 0.9007 - val_loss: 0.1613 - val_accuracy: 0.9340\n",
      "Epoch 120/200\n",
      "5416/5416 [==============================] - 153s 28ms/step - loss: 0.2233 - accuracy: 0.9024 - val_loss: 0.1599 - val_accuracy: 0.9352\n",
      "Epoch 121/200\n",
      "5416/5416 [==============================] - 152s 28ms/step - loss: 0.2232 - accuracy: 0.9022 - val_loss: 0.1596 - val_accuracy: 0.9360\n",
      "Epoch 122/200\n",
      "5416/5416 [==============================] - 152s 28ms/step - loss: 0.2199 - accuracy: 0.9030 - val_loss: 0.1565 - val_accuracy: 0.9387\n",
      "Epoch 123/200\n",
      "5416/5416 [==============================] - 152s 28ms/step - loss: 0.2183 - accuracy: 0.9043 - val_loss: 0.1555 - val_accuracy: 0.9381\n",
      "Epoch 124/200\n",
      "1123/5416 [=====>........................] - ETA: 1:23 - loss: 0.2015 - accuracy: 0.9117"
     ]
    }
   ],
   "source": [
    "core.retrain_model(model_base_id, kt_iter, db_ver, ROOT_PATH=ROOT_PATH, DB_ROOT_PATH=DB_ROOT_PATH, dataset_size=dataset_size, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, retrain_epochs=retrain_epochs, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbcfc88e-a594-4eaa-928d-a643bf26ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id='326'\n",
    "kt_iter='33'\n",
    "db_ver='8'\n",
    "ROOT_PATH = './'\n",
    "DB_ROOT_PATH = 'J:\\#PROJECT\\idx'\n",
    "dataset_size = 'full_new_wsd'\n",
    "batch_size = 64\n",
    "shuffle_buffer_size = 2048\n",
    "retrain_epochs = 300\n",
    "generator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f986ff0-667b-41e0-8849-28be9470461a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 423\n",
      "Total constituents: 423\n",
      "Load model from keras_tuner\n",
      "Epoch 1/300\n",
      "5416/5416 [==============================] - 99s 18ms/step - loss: 0.6551 - accuracy: 0.5897 - val_loss: 0.6401 - val_accuracy: 0.6077\n",
      "Epoch 2/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6425 - accuracy: 0.6033 - val_loss: 0.6383 - val_accuracy: 0.6069\n",
      "Epoch 3/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6379 - accuracy: 0.6096 - val_loss: 0.6313 - val_accuracy: 0.6195\n",
      "Epoch 4/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6355 - accuracy: 0.6136 - val_loss: 0.6294 - val_accuracy: 0.6197\n",
      "Epoch 5/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6330 - accuracy: 0.6146 - val_loss: 0.6263 - val_accuracy: 0.6227\n",
      "Epoch 6/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6312 - accuracy: 0.6163 - val_loss: 0.6238 - val_accuracy: 0.6252\n",
      "Epoch 7/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6295 - accuracy: 0.6189 - val_loss: 0.6222 - val_accuracy: 0.6282\n",
      "Epoch 8/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6270 - accuracy: 0.6207 - val_loss: 0.6220 - val_accuracy: 0.6265\n",
      "Epoch 9/300\n",
      "5416/5416 [==============================] - 93s 17ms/step - loss: 0.6253 - accuracy: 0.6229 - val_loss: 0.6167 - val_accuracy: 0.6332\n",
      "Epoch 10/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6230 - accuracy: 0.6245 - val_loss: 0.6140 - val_accuracy: 0.6359\n",
      "Epoch 11/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6206 - accuracy: 0.6278 - val_loss: 0.6117 - val_accuracy: 0.6383\n",
      "Epoch 12/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6180 - accuracy: 0.6300 - val_loss: 0.6086 - val_accuracy: 0.6423\n",
      "Epoch 13/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6156 - accuracy: 0.6323 - val_loss: 0.6053 - val_accuracy: 0.6441\n",
      "Epoch 14/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6129 - accuracy: 0.6362 - val_loss: 0.6028 - val_accuracy: 0.6470\n",
      "Epoch 15/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6116 - accuracy: 0.6372 - val_loss: 0.5997 - val_accuracy: 0.6501\n",
      "Epoch 16/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6082 - accuracy: 0.6412 - val_loss: 0.5959 - val_accuracy: 0.6546\n",
      "Epoch 17/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.6059 - accuracy: 0.6437 - val_loss: 0.5926 - val_accuracy: 0.6576\n",
      "Epoch 18/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.6033 - accuracy: 0.6469 - val_loss: 0.5874 - val_accuracy: 0.6627\n",
      "Epoch 19/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5998 - accuracy: 0.6500 - val_loss: 0.5896 - val_accuracy: 0.6603\n",
      "Epoch 20/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5971 - accuracy: 0.6541 - val_loss: 0.5815 - val_accuracy: 0.6685\n",
      "Epoch 21/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5945 - accuracy: 0.6549 - val_loss: 0.5772 - val_accuracy: 0.6730\n",
      "Epoch 22/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5913 - accuracy: 0.6590 - val_loss: 0.5743 - val_accuracy: 0.6754\n",
      "Epoch 23/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5882 - accuracy: 0.6630 - val_loss: 0.5710 - val_accuracy: 0.6782\n",
      "Epoch 24/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5849 - accuracy: 0.6661 - val_loss: 0.5669 - val_accuracy: 0.6834\n",
      "Epoch 25/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5812 - accuracy: 0.6683 - val_loss: 0.5622 - val_accuracy: 0.6876\n",
      "Epoch 26/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5791 - accuracy: 0.6711 - val_loss: 0.5586 - val_accuracy: 0.6924\n",
      "Epoch 27/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5754 - accuracy: 0.6758 - val_loss: 0.5546 - val_accuracy: 0.6953\n",
      "Epoch 28/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5725 - accuracy: 0.6774 - val_loss: 0.5492 - val_accuracy: 0.6990\n",
      "Epoch 29/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5697 - accuracy: 0.6799 - val_loss: 0.5464 - val_accuracy: 0.7019\n",
      "Epoch 30/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5658 - accuracy: 0.6834 - val_loss: 0.5403 - val_accuracy: 0.7069\n",
      "Epoch 31/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5629 - accuracy: 0.6864 - val_loss: 0.5384 - val_accuracy: 0.7098\n",
      "Epoch 32/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5595 - accuracy: 0.6895 - val_loss: 0.5341 - val_accuracy: 0.7129\n",
      "Epoch 33/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5560 - accuracy: 0.6920 - val_loss: 0.5299 - val_accuracy: 0.7165\n",
      "Epoch 34/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5536 - accuracy: 0.6928 - val_loss: 0.5264 - val_accuracy: 0.7180\n",
      "Epoch 35/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5502 - accuracy: 0.6971 - val_loss: 0.5211 - val_accuracy: 0.7234\n",
      "Epoch 36/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5475 - accuracy: 0.6998 - val_loss: 0.5186 - val_accuracy: 0.7242\n",
      "Epoch 37/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5442 - accuracy: 0.7025 - val_loss: 0.5136 - val_accuracy: 0.7276\n",
      "Epoch 38/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5412 - accuracy: 0.7049 - val_loss: 0.5088 - val_accuracy: 0.7313\n",
      "Epoch 39/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5378 - accuracy: 0.7069 - val_loss: 0.5064 - val_accuracy: 0.7323\n",
      "Epoch 40/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5358 - accuracy: 0.7086 - val_loss: 0.5048 - val_accuracy: 0.7341\n",
      "Epoch 41/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5327 - accuracy: 0.7116 - val_loss: 0.5018 - val_accuracy: 0.7365\n",
      "Epoch 42/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5302 - accuracy: 0.7144 - val_loss: 0.5009 - val_accuracy: 0.7376\n",
      "Epoch 43/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5280 - accuracy: 0.7149 - val_loss: 0.4904 - val_accuracy: 0.7461\n",
      "Epoch 44/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5238 - accuracy: 0.7181 - val_loss: 0.4878 - val_accuracy: 0.7470\n",
      "Epoch 45/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5214 - accuracy: 0.7202 - val_loss: 0.4835 - val_accuracy: 0.7499\n",
      "Epoch 46/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5185 - accuracy: 0.7204 - val_loss: 0.4837 - val_accuracy: 0.7517\n",
      "Epoch 47/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5161 - accuracy: 0.7252 - val_loss: 0.4839 - val_accuracy: 0.7505\n",
      "Epoch 48/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5133 - accuracy: 0.7248 - val_loss: 0.4765 - val_accuracy: 0.7565\n",
      "Epoch 49/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5108 - accuracy: 0.7282 - val_loss: 0.4707 - val_accuracy: 0.7592\n",
      "Epoch 50/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5075 - accuracy: 0.7300 - val_loss: 0.4686 - val_accuracy: 0.7598\n",
      "Epoch 51/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5062 - accuracy: 0.7308 - val_loss: 0.4666 - val_accuracy: 0.7622\n",
      "Epoch 52/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5043 - accuracy: 0.7336 - val_loss: 0.4636 - val_accuracy: 0.7642\n",
      "Epoch 53/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.5014 - accuracy: 0.7354 - val_loss: 0.4639 - val_accuracy: 0.7644\n",
      "Epoch 54/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4986 - accuracy: 0.7370 - val_loss: 0.4559 - val_accuracy: 0.7697\n",
      "Epoch 55/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4968 - accuracy: 0.7378 - val_loss: 0.4543 - val_accuracy: 0.7691\n",
      "Epoch 56/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4938 - accuracy: 0.7411 - val_loss: 0.4498 - val_accuracy: 0.7716\n",
      "Epoch 57/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4923 - accuracy: 0.7413 - val_loss: 0.4498 - val_accuracy: 0.7729\n",
      "Epoch 58/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4899 - accuracy: 0.7430 - val_loss: 0.4509 - val_accuracy: 0.7715\n",
      "Epoch 59/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4876 - accuracy: 0.7448 - val_loss: 0.4400 - val_accuracy: 0.7779\n",
      "Epoch 60/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4849 - accuracy: 0.7460 - val_loss: 0.4410 - val_accuracy: 0.7792\n",
      "Epoch 61/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4827 - accuracy: 0.7469 - val_loss: 0.4425 - val_accuracy: 0.7779\n",
      "Epoch 62/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4807 - accuracy: 0.7488 - val_loss: 0.4395 - val_accuracy: 0.7804\n",
      "Epoch 63/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4783 - accuracy: 0.7521 - val_loss: 0.4304 - val_accuracy: 0.7847\n",
      "Epoch 64/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4771 - accuracy: 0.7513 - val_loss: 0.4331 - val_accuracy: 0.7847\n",
      "Epoch 65/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4744 - accuracy: 0.7539 - val_loss: 0.4319 - val_accuracy: 0.7854\n",
      "Epoch 66/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4726 - accuracy: 0.7536 - val_loss: 0.4246 - val_accuracy: 0.7897\n",
      "Epoch 67/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4703 - accuracy: 0.7573 - val_loss: 0.4260 - val_accuracy: 0.7889\n",
      "Epoch 68/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4690 - accuracy: 0.7577 - val_loss: 0.4227 - val_accuracy: 0.7898\n",
      "Epoch 69/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4672 - accuracy: 0.7590 - val_loss: 0.4200 - val_accuracy: 0.7944\n",
      "Epoch 70/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4649 - accuracy: 0.7607 - val_loss: 0.4194 - val_accuracy: 0.7933\n",
      "Epoch 71/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4635 - accuracy: 0.7613 - val_loss: 0.4109 - val_accuracy: 0.7977\n",
      "Epoch 72/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4608 - accuracy: 0.7632 - val_loss: 0.4136 - val_accuracy: 0.7970\n",
      "Epoch 73/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4592 - accuracy: 0.7636 - val_loss: 0.4134 - val_accuracy: 0.7962\n",
      "Epoch 74/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4580 - accuracy: 0.7647 - val_loss: 0.4071 - val_accuracy: 0.8008\n",
      "Epoch 75/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4566 - accuracy: 0.7655 - val_loss: 0.4089 - val_accuracy: 0.7989\n",
      "Epoch 76/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4553 - accuracy: 0.7659 - val_loss: 0.4053 - val_accuracy: 0.8019\n",
      "Epoch 77/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4535 - accuracy: 0.7673 - val_loss: 0.4074 - val_accuracy: 0.7992\n",
      "Epoch 78/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4518 - accuracy: 0.7687 - val_loss: 0.4019 - val_accuracy: 0.8028\n",
      "Epoch 79/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4504 - accuracy: 0.7699 - val_loss: 0.3997 - val_accuracy: 0.8047\n",
      "Epoch 80/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4471 - accuracy: 0.7712 - val_loss: 0.3982 - val_accuracy: 0.8066\n",
      "Epoch 81/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4468 - accuracy: 0.7728 - val_loss: 0.3943 - val_accuracy: 0.8079\n",
      "Epoch 82/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4450 - accuracy: 0.7728 - val_loss: 0.3949 - val_accuracy: 0.8078\n",
      "Epoch 83/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4435 - accuracy: 0.7738 - val_loss: 0.3957 - val_accuracy: 0.8057\n",
      "Epoch 84/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4421 - accuracy: 0.7754 - val_loss: 0.3916 - val_accuracy: 0.8100\n",
      "Epoch 85/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4402 - accuracy: 0.7766 - val_loss: 0.3860 - val_accuracy: 0.8130\n",
      "Epoch 86/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4378 - accuracy: 0.7780 - val_loss: 0.3859 - val_accuracy: 0.8147\n",
      "Epoch 87/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4378 - accuracy: 0.7782 - val_loss: 0.3836 - val_accuracy: 0.8145\n",
      "Epoch 88/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4356 - accuracy: 0.7783 - val_loss: 0.3802 - val_accuracy: 0.8176\n",
      "Epoch 89/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4348 - accuracy: 0.7796 - val_loss: 0.3821 - val_accuracy: 0.8147\n",
      "Epoch 90/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4320 - accuracy: 0.7808 - val_loss: 0.3801 - val_accuracy: 0.8159\n",
      "Epoch 91/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4303 - accuracy: 0.7825 - val_loss: 0.3746 - val_accuracy: 0.8182\n",
      "Epoch 92/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4301 - accuracy: 0.7822 - val_loss: 0.3760 - val_accuracy: 0.8185\n",
      "Epoch 93/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.4292 - accuracy: 0.7829 - val_loss: 0.3712 - val_accuracy: 0.8219\n",
      "Epoch 94/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4291 - accuracy: 0.7832 - val_loss: 0.3703 - val_accuracy: 0.8216\n",
      "Epoch 95/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4263 - accuracy: 0.7842 - val_loss: 0.3696 - val_accuracy: 0.8244\n",
      "Epoch 96/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4260 - accuracy: 0.7848 - val_loss: 0.3698 - val_accuracy: 0.8243\n",
      "Epoch 97/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4227 - accuracy: 0.7871 - val_loss: 0.3664 - val_accuracy: 0.8248\n",
      "Epoch 98/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4233 - accuracy: 0.7876 - val_loss: 0.3688 - val_accuracy: 0.8237\n",
      "Epoch 99/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4206 - accuracy: 0.7886 - val_loss: 0.3708 - val_accuracy: 0.8210\n",
      "Epoch 100/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4202 - accuracy: 0.7888 - val_loss: 0.3628 - val_accuracy: 0.8265\n",
      "Epoch 101/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4190 - accuracy: 0.7904 - val_loss: 0.3587 - val_accuracy: 0.8291\n",
      "Epoch 102/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4166 - accuracy: 0.7905 - val_loss: 0.3640 - val_accuracy: 0.8266\n",
      "Epoch 103/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4179 - accuracy: 0.7916 - val_loss: 0.3614 - val_accuracy: 0.8289\n",
      "Epoch 104/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4154 - accuracy: 0.7922 - val_loss: 0.3578 - val_accuracy: 0.8299\n",
      "Epoch 105/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4135 - accuracy: 0.7926 - val_loss: 0.3587 - val_accuracy: 0.8296\n",
      "Epoch 106/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.4123 - accuracy: 0.7946 - val_loss: 0.3551 - val_accuracy: 0.8301\n",
      "Epoch 107/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.4114 - accuracy: 0.7937 - val_loss: 0.3522 - val_accuracy: 0.8316\n",
      "Epoch 108/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4105 - accuracy: 0.7959 - val_loss: 0.3487 - val_accuracy: 0.8347\n",
      "Epoch 109/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4106 - accuracy: 0.7953 - val_loss: 0.3508 - val_accuracy: 0.8335\n",
      "Epoch 110/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4080 - accuracy: 0.7957 - val_loss: 0.3523 - val_accuracy: 0.8335\n",
      "Epoch 111/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4072 - accuracy: 0.7973 - val_loss: 0.3513 - val_accuracy: 0.8347\n",
      "Epoch 112/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4063 - accuracy: 0.7981 - val_loss: 0.3457 - val_accuracy: 0.8373\n",
      "Epoch 113/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4047 - accuracy: 0.7982 - val_loss: 0.3468 - val_accuracy: 0.8382\n",
      "Epoch 114/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4032 - accuracy: 0.7998 - val_loss: 0.3436 - val_accuracy: 0.8381\n",
      "Epoch 115/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4035 - accuracy: 0.7996 - val_loss: 0.3440 - val_accuracy: 0.8383\n",
      "Epoch 116/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.4012 - accuracy: 0.7999 - val_loss: 0.3468 - val_accuracy: 0.8363\n",
      "Epoch 117/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.4007 - accuracy: 0.8016 - val_loss: 0.3405 - val_accuracy: 0.8399\n",
      "Epoch 118/300\n",
      "5416/5416 [==============================] - 96s 18ms/step - loss: 0.4005 - accuracy: 0.8006 - val_loss: 0.3448 - val_accuracy: 0.8390\n",
      "Epoch 119/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3990 - accuracy: 0.8024 - val_loss: 0.3367 - val_accuracy: 0.8411\n",
      "Epoch 120/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3974 - accuracy: 0.8034 - val_loss: 0.3411 - val_accuracy: 0.8392\n",
      "Epoch 121/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3990 - accuracy: 0.8014 - val_loss: 0.3400 - val_accuracy: 0.8394\n",
      "Epoch 122/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3957 - accuracy: 0.8041 - val_loss: 0.3368 - val_accuracy: 0.8418\n",
      "Epoch 123/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3967 - accuracy: 0.8034 - val_loss: 0.3352 - val_accuracy: 0.8446\n",
      "Epoch 124/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3949 - accuracy: 0.8044 - val_loss: 0.3286 - val_accuracy: 0.8465\n",
      "Epoch 125/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3937 - accuracy: 0.8054 - val_loss: 0.3324 - val_accuracy: 0.8445\n",
      "Epoch 126/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3932 - accuracy: 0.8047 - val_loss: 0.3389 - val_accuracy: 0.8414\n",
      "Epoch 127/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3981 - accuracy: 0.8025 - val_loss: 0.3240 - val_accuracy: 0.8489\n",
      "Epoch 128/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3876 - accuracy: 0.8090 - val_loss: 0.3285 - val_accuracy: 0.8475\n",
      "Epoch 129/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3909 - accuracy: 0.8069 - val_loss: 0.3289 - val_accuracy: 0.8472\n",
      "Epoch 130/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3909 - accuracy: 0.8054 - val_loss: 0.3323 - val_accuracy: 0.8462\n",
      "Epoch 131/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3907 - accuracy: 0.8077 - val_loss: 0.3305 - val_accuracy: 0.8456\n",
      "Epoch 132/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3896 - accuracy: 0.8073 - val_loss: 0.3243 - val_accuracy: 0.8494\n",
      "Epoch 133/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3878 - accuracy: 0.8091 - val_loss: 0.3258 - val_accuracy: 0.8503\n",
      "Epoch 134/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3875 - accuracy: 0.8103 - val_loss: 0.3264 - val_accuracy: 0.8487\n",
      "Epoch 135/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3866 - accuracy: 0.8098 - val_loss: 0.3259 - val_accuracy: 0.8502\n",
      "Epoch 136/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3872 - accuracy: 0.8097 - val_loss: 0.3285 - val_accuracy: 0.8476\n",
      "Epoch 137/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3851 - accuracy: 0.8103 - val_loss: 0.3197 - val_accuracy: 0.8524\n",
      "Epoch 138/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3857 - accuracy: 0.8103 - val_loss: 0.3213 - val_accuracy: 0.8511\n",
      "Epoch 139/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3837 - accuracy: 0.8119 - val_loss: 0.3227 - val_accuracy: 0.8492\n",
      "Epoch 140/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3822 - accuracy: 0.8126 - val_loss: 0.3190 - val_accuracy: 0.8513\n",
      "Epoch 141/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3812 - accuracy: 0.8131 - val_loss: 0.3181 - val_accuracy: 0.8512\n",
      "Epoch 142/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3806 - accuracy: 0.8130 - val_loss: 0.3154 - val_accuracy: 0.8548\n",
      "Epoch 143/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3813 - accuracy: 0.8124 - val_loss: 0.3212 - val_accuracy: 0.8521\n",
      "Epoch 144/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3809 - accuracy: 0.8137 - val_loss: 0.3188 - val_accuracy: 0.8531\n",
      "Epoch 145/300\n",
      "5416/5416 [==============================] - 97s 18ms/step - loss: 0.3787 - accuracy: 0.8141 - val_loss: 0.3157 - val_accuracy: 0.8546\n",
      "Epoch 146/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3798 - accuracy: 0.8151 - val_loss: 0.3172 - val_accuracy: 0.8539\n",
      "Epoch 147/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3780 - accuracy: 0.8140 - val_loss: 0.3146 - val_accuracy: 0.8530\n",
      "Epoch 148/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3768 - accuracy: 0.8153 - val_loss: 0.3201 - val_accuracy: 0.8529\n",
      "Epoch 149/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3751 - accuracy: 0.8151 - val_loss: 0.3106 - val_accuracy: 0.8557\n",
      "Epoch 150/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3776 - accuracy: 0.8161 - val_loss: 0.3105 - val_accuracy: 0.8588\n",
      "Epoch 151/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3755 - accuracy: 0.8165 - val_loss: 0.3112 - val_accuracy: 0.8570\n",
      "Epoch 152/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3761 - accuracy: 0.8162 - val_loss: 0.3106 - val_accuracy: 0.8570\n",
      "Epoch 153/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3760 - accuracy: 0.8163 - val_loss: 0.3091 - val_accuracy: 0.8586\n",
      "Epoch 154/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3729 - accuracy: 0.8178 - val_loss: 0.3082 - val_accuracy: 0.8589\n",
      "Epoch 155/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3707 - accuracy: 0.8184 - val_loss: 0.3094 - val_accuracy: 0.8591\n",
      "Epoch 156/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3716 - accuracy: 0.8182 - val_loss: 0.3037 - val_accuracy: 0.8612\n",
      "Epoch 157/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3714 - accuracy: 0.8193 - val_loss: 0.3061 - val_accuracy: 0.8590\n",
      "Epoch 158/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3682 - accuracy: 0.8203 - val_loss: 0.3074 - val_accuracy: 0.8580\n",
      "Epoch 159/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3685 - accuracy: 0.8205 - val_loss: 0.3053 - val_accuracy: 0.8600\n",
      "Epoch 160/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3695 - accuracy: 0.8194 - val_loss: 0.3037 - val_accuracy: 0.8610\n",
      "Epoch 161/300\n",
      "5416/5416 [==============================] - 99s 18ms/step - loss: 0.3686 - accuracy: 0.8204 - val_loss: 0.3023 - val_accuracy: 0.8628\n",
      "Epoch 162/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3679 - accuracy: 0.8209 - val_loss: 0.3004 - val_accuracy: 0.8627\n",
      "Epoch 163/300\n",
      "5416/5416 [==============================] - 97s 18ms/step - loss: 0.3686 - accuracy: 0.8210 - val_loss: 0.3048 - val_accuracy: 0.8613\n",
      "Epoch 164/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3663 - accuracy: 0.8220 - val_loss: 0.3019 - val_accuracy: 0.8630\n",
      "Epoch 165/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3668 - accuracy: 0.8216 - val_loss: 0.3007 - val_accuracy: 0.8634\n",
      "Epoch 166/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3657 - accuracy: 0.8219 - val_loss: 0.3011 - val_accuracy: 0.8623\n",
      "Epoch 167/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3663 - accuracy: 0.8215 - val_loss: 0.3031 - val_accuracy: 0.8610\n",
      "Epoch 168/300\n",
      "5416/5416 [==============================] - 96s 18ms/step - loss: 0.3636 - accuracy: 0.8242 - val_loss: 0.3013 - val_accuracy: 0.8641\n",
      "Epoch 169/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3620 - accuracy: 0.8231 - val_loss: 0.3012 - val_accuracy: 0.8624\n",
      "Epoch 170/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3637 - accuracy: 0.8237 - val_loss: 0.2975 - val_accuracy: 0.8660\n",
      "Epoch 171/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3697 - accuracy: 0.8202 - val_loss: 0.2989 - val_accuracy: 0.8661\n",
      "Epoch 172/300\n",
      "5416/5416 [==============================] - 98s 18ms/step - loss: 0.3617 - accuracy: 0.8239 - val_loss: 0.2986 - val_accuracy: 0.8635\n",
      "Epoch 173/300\n",
      "5416/5416 [==============================] - 99s 18ms/step - loss: 0.3625 - accuracy: 0.8231 - val_loss: 0.2958 - val_accuracy: 0.8655\n",
      "Epoch 174/300\n",
      "5416/5416 [==============================] - 100s 18ms/step - loss: 0.3623 - accuracy: 0.8240 - val_loss: 0.2976 - val_accuracy: 0.8661\n",
      "Epoch 175/300\n",
      "5416/5416 [==============================] - 100s 18ms/step - loss: 0.3627 - accuracy: 0.8238 - val_loss: 0.3015 - val_accuracy: 0.8622\n",
      "Epoch 176/300\n",
      "5416/5416 [==============================] - 99s 18ms/step - loss: 0.3597 - accuracy: 0.8252 - val_loss: 0.2893 - val_accuracy: 0.8694\n",
      "Epoch 177/300\n",
      "5416/5416 [==============================] - 99s 18ms/step - loss: 0.3597 - accuracy: 0.8259 - val_loss: 0.2938 - val_accuracy: 0.8673\n",
      "Epoch 178/300\n",
      "5416/5416 [==============================] - 100s 18ms/step - loss: 0.3600 - accuracy: 0.8257 - val_loss: 0.2925 - val_accuracy: 0.8673\n",
      "Epoch 179/300\n",
      "5416/5416 [==============================] - 99s 18ms/step - loss: 0.3596 - accuracy: 0.8256 - val_loss: 0.2909 - val_accuracy: 0.8687\n",
      "Epoch 180/300\n",
      "5416/5416 [==============================] - 97s 18ms/step - loss: 0.3585 - accuracy: 0.8270 - val_loss: 0.2907 - val_accuracy: 0.8683\n",
      "Epoch 181/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3575 - accuracy: 0.8276 - val_loss: 0.2918 - val_accuracy: 0.8692\n",
      "Epoch 182/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3572 - accuracy: 0.8259 - val_loss: 0.2894 - val_accuracy: 0.8681\n",
      "Epoch 183/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3561 - accuracy: 0.8281 - val_loss: 0.2895 - val_accuracy: 0.8684\n",
      "Epoch 184/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3567 - accuracy: 0.8284 - val_loss: 0.2893 - val_accuracy: 0.8686\n",
      "Epoch 185/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3557 - accuracy: 0.8285 - val_loss: 0.2873 - val_accuracy: 0.8708\n",
      "Epoch 186/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3541 - accuracy: 0.8283 - val_loss: 0.2927 - val_accuracy: 0.8692\n",
      "Epoch 187/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3528 - accuracy: 0.8287 - val_loss: 0.2854 - val_accuracy: 0.8697\n",
      "Epoch 188/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3530 - accuracy: 0.8290 - val_loss: 0.2852 - val_accuracy: 0.8713\n",
      "Epoch 189/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3532 - accuracy: 0.8286 - val_loss: 0.2859 - val_accuracy: 0.8703\n",
      "Epoch 190/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3516 - accuracy: 0.8296 - val_loss: 0.2813 - val_accuracy: 0.8721\n",
      "Epoch 191/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3521 - accuracy: 0.8298 - val_loss: 0.2898 - val_accuracy: 0.8685\n",
      "Epoch 192/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3524 - accuracy: 0.8300 - val_loss: 0.2930 - val_accuracy: 0.8663\n",
      "Epoch 193/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3518 - accuracy: 0.8298 - val_loss: 0.2814 - val_accuracy: 0.8739\n",
      "Epoch 194/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3522 - accuracy: 0.8303 - val_loss: 0.2814 - val_accuracy: 0.8726\n",
      "Epoch 195/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3499 - accuracy: 0.8316 - val_loss: 0.2849 - val_accuracy: 0.8716\n",
      "Epoch 196/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3503 - accuracy: 0.8314 - val_loss: 0.2820 - val_accuracy: 0.8734\n",
      "Epoch 197/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3502 - accuracy: 0.8313 - val_loss: 0.2811 - val_accuracy: 0.8737\n",
      "Epoch 198/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3485 - accuracy: 0.8315 - val_loss: 0.2817 - val_accuracy: 0.8726\n",
      "Epoch 199/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3494 - accuracy: 0.8313 - val_loss: 0.2811 - val_accuracy: 0.8734\n",
      "Epoch 200/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3485 - accuracy: 0.8327 - val_loss: 0.2821 - val_accuracy: 0.8742\n",
      "Epoch 201/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3486 - accuracy: 0.8320 - val_loss: 0.2765 - val_accuracy: 0.8772\n",
      "Epoch 202/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3543 - accuracy: 0.8293 - val_loss: 0.2796 - val_accuracy: 0.8754\n",
      "Epoch 203/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3461 - accuracy: 0.8331 - val_loss: 0.2797 - val_accuracy: 0.8744\n",
      "Epoch 204/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3475 - accuracy: 0.8310 - val_loss: 0.2809 - val_accuracy: 0.8752\n",
      "Epoch 205/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3472 - accuracy: 0.8325 - val_loss: 0.2761 - val_accuracy: 0.8756\n",
      "Epoch 206/300\n",
      "5416/5416 [==============================] - 96s 18ms/step - loss: 0.3452 - accuracy: 0.8343 - val_loss: 0.2769 - val_accuracy: 0.8759\n",
      "Epoch 207/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3459 - accuracy: 0.8337 - val_loss: 0.2795 - val_accuracy: 0.8742\n",
      "Epoch 208/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3465 - accuracy: 0.8328 - val_loss: 0.2783 - val_accuracy: 0.8758\n",
      "Epoch 209/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3436 - accuracy: 0.8345 - val_loss: 0.2788 - val_accuracy: 0.8763\n",
      "Epoch 210/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3447 - accuracy: 0.8344 - val_loss: 0.2752 - val_accuracy: 0.8764\n",
      "Epoch 211/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3438 - accuracy: 0.8358 - val_loss: 0.2746 - val_accuracy: 0.8781\n",
      "Epoch 212/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3431 - accuracy: 0.8351 - val_loss: 0.2725 - val_accuracy: 0.8789\n",
      "Epoch 213/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3427 - accuracy: 0.8349 - val_loss: 0.2733 - val_accuracy: 0.8781\n",
      "Epoch 214/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3427 - accuracy: 0.8353 - val_loss: 0.2779 - val_accuracy: 0.8770\n",
      "Epoch 215/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3429 - accuracy: 0.8359 - val_loss: 0.2724 - val_accuracy: 0.8779\n",
      "Epoch 216/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3429 - accuracy: 0.8359 - val_loss: 0.2739 - val_accuracy: 0.8769\n",
      "Epoch 217/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3407 - accuracy: 0.8367 - val_loss: 0.2755 - val_accuracy: 0.8769\n",
      "Epoch 218/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3427 - accuracy: 0.8365 - val_loss: 0.2702 - val_accuracy: 0.8796\n",
      "Epoch 219/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3407 - accuracy: 0.8367 - val_loss: 0.2720 - val_accuracy: 0.8800\n",
      "Epoch 220/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3399 - accuracy: 0.8371 - val_loss: 0.2682 - val_accuracy: 0.8803\n",
      "Epoch 221/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3396 - accuracy: 0.8373 - val_loss: 0.2689 - val_accuracy: 0.8791\n",
      "Epoch 222/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3409 - accuracy: 0.8368 - val_loss: 0.2695 - val_accuracy: 0.8807\n",
      "Epoch 223/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3399 - accuracy: 0.8372 - val_loss: 0.2713 - val_accuracy: 0.8793\n",
      "Epoch 224/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3395 - accuracy: 0.8378 - val_loss: 0.2749 - val_accuracy: 0.8782\n",
      "Epoch 225/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3398 - accuracy: 0.8374 - val_loss: 0.2659 - val_accuracy: 0.8819\n",
      "Epoch 226/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3404 - accuracy: 0.8366 - val_loss: 0.2701 - val_accuracy: 0.8793\n",
      "Epoch 227/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3384 - accuracy: 0.8382 - val_loss: 0.2689 - val_accuracy: 0.8801\n",
      "Epoch 228/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3378 - accuracy: 0.8383 - val_loss: 0.2631 - val_accuracy: 0.8829\n",
      "Epoch 229/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3380 - accuracy: 0.8380 - val_loss: 0.2700 - val_accuracy: 0.8796\n",
      "Epoch 230/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3369 - accuracy: 0.8385 - val_loss: 0.2674 - val_accuracy: 0.8805\n",
      "Epoch 231/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3363 - accuracy: 0.8389 - val_loss: 0.2688 - val_accuracy: 0.8792\n",
      "Epoch 232/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3348 - accuracy: 0.8401 - val_loss: 0.2658 - val_accuracy: 0.8817\n",
      "Epoch 233/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3353 - accuracy: 0.8392 - val_loss: 0.2657 - val_accuracy: 0.8828\n",
      "Epoch 234/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3360 - accuracy: 0.8395 - val_loss: 0.2643 - val_accuracy: 0.8827\n",
      "Epoch 235/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3366 - accuracy: 0.8397 - val_loss: 0.2693 - val_accuracy: 0.8803\n",
      "Epoch 236/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3376 - accuracy: 0.8389 - val_loss: 0.2691 - val_accuracy: 0.8816\n",
      "Epoch 237/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3395 - accuracy: 0.8381 - val_loss: 0.2620 - val_accuracy: 0.8849\n",
      "Epoch 238/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3372 - accuracy: 0.8399 - val_loss: 0.2696 - val_accuracy: 0.8802\n",
      "Epoch 239/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3347 - accuracy: 0.8407 - val_loss: 0.2647 - val_accuracy: 0.8828\n",
      "Epoch 240/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3368 - accuracy: 0.8390 - val_loss: 0.2662 - val_accuracy: 0.8810\n",
      "Epoch 241/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3347 - accuracy: 0.8408 - val_loss: 0.2662 - val_accuracy: 0.8821\n",
      "Epoch 242/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3348 - accuracy: 0.8399 - val_loss: 0.2717 - val_accuracy: 0.8790\n",
      "Epoch 243/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3349 - accuracy: 0.8406 - val_loss: 0.2645 - val_accuracy: 0.8822\n",
      "Epoch 244/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3332 - accuracy: 0.8412 - val_loss: 0.2637 - val_accuracy: 0.8834\n",
      "Epoch 245/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3339 - accuracy: 0.8417 - val_loss: 0.2653 - val_accuracy: 0.8823\n",
      "Epoch 246/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3382 - accuracy: 0.8396 - val_loss: 0.2815 - val_accuracy: 0.8755\n",
      "Epoch 247/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3550 - accuracy: 0.8297 - val_loss: 0.2826 - val_accuracy: 0.8756\n",
      "Epoch 248/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3441 - accuracy: 0.8359 - val_loss: 0.2765 - val_accuracy: 0.8774\n",
      "Epoch 249/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3484 - accuracy: 0.8348 - val_loss: 0.2694 - val_accuracy: 0.8810\n",
      "Epoch 250/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3525 - accuracy: 0.8321 - val_loss: 0.2977 - val_accuracy: 0.8676\n",
      "Epoch 251/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3550 - accuracy: 0.8307 - val_loss: 0.2789 - val_accuracy: 0.8755\n",
      "Epoch 252/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3490 - accuracy: 0.8334 - val_loss: 0.2924 - val_accuracy: 0.8692\n",
      "Epoch 253/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3427 - accuracy: 0.8368 - val_loss: 0.2747 - val_accuracy: 0.8783\n",
      "Epoch 254/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3407 - accuracy: 0.8370 - val_loss: 0.2679 - val_accuracy: 0.8821\n",
      "Epoch 255/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3403 - accuracy: 0.8381 - val_loss: 0.2650 - val_accuracy: 0.8832\n",
      "Epoch 256/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3364 - accuracy: 0.8405 - val_loss: 0.2680 - val_accuracy: 0.8812\n",
      "Epoch 257/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3414 - accuracy: 0.8368 - val_loss: 0.2635 - val_accuracy: 0.8831\n",
      "Epoch 258/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3335 - accuracy: 0.8411 - val_loss: 0.2670 - val_accuracy: 0.8828\n",
      "Epoch 259/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3333 - accuracy: 0.8411 - val_loss: 0.2685 - val_accuracy: 0.8817\n",
      "Epoch 260/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3355 - accuracy: 0.8403 - val_loss: 0.2634 - val_accuracy: 0.8831\n",
      "Epoch 261/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3324 - accuracy: 0.8413 - val_loss: 0.2613 - val_accuracy: 0.8850\n",
      "Epoch 262/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3318 - accuracy: 0.8420 - val_loss: 0.2600 - val_accuracy: 0.8849\n",
      "Epoch 263/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3309 - accuracy: 0.8431 - val_loss: 0.2623 - val_accuracy: 0.8853\n",
      "Epoch 264/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3318 - accuracy: 0.8425 - val_loss: 0.2616 - val_accuracy: 0.8845\n",
      "Epoch 265/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3297 - accuracy: 0.8435 - val_loss: 0.2646 - val_accuracy: 0.8830\n",
      "Epoch 266/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.3307 - accuracy: 0.8431 - val_loss: 0.2566 - val_accuracy: 0.8884\n",
      "Epoch 267/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3288 - accuracy: 0.8438 - val_loss: 0.2563 - val_accuracy: 0.8879\n",
      "Epoch 268/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3345 - accuracy: 0.8409 - val_loss: 0.2579 - val_accuracy: 0.8884\n",
      "Epoch 269/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3504 - accuracy: 0.8327 - val_loss: 0.2687 - val_accuracy: 0.8820\n",
      "Epoch 270/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3434 - accuracy: 0.8366 - val_loss: 0.2809 - val_accuracy: 0.8748\n",
      "Epoch 271/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3380 - accuracy: 0.8390 - val_loss: 0.2855 - val_accuracy: 0.8734\n",
      "Epoch 272/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3391 - accuracy: 0.8386 - val_loss: 0.2738 - val_accuracy: 0.8796\n",
      "Epoch 273/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3396 - accuracy: 0.8396 - val_loss: 0.2633 - val_accuracy: 0.8844\n",
      "Epoch 274/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3389 - accuracy: 0.8392 - val_loss: 0.2879 - val_accuracy: 0.8729\n",
      "Epoch 275/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3375 - accuracy: 0.8394 - val_loss: 0.2625 - val_accuracy: 0.8835\n",
      "Epoch 276/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3323 - accuracy: 0.8420 - val_loss: 0.2630 - val_accuracy: 0.8856\n",
      "Epoch 277/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3341 - accuracy: 0.8414 - val_loss: 0.2791 - val_accuracy: 0.8761\n",
      "Epoch 278/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3311 - accuracy: 0.8438 - val_loss: 0.2603 - val_accuracy: 0.8857\n",
      "Epoch 279/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3299 - accuracy: 0.8444 - val_loss: 0.2575 - val_accuracy: 0.8872\n",
      "Epoch 280/300\n",
      "5416/5416 [==============================] - 96s 18ms/step - loss: 0.3323 - accuracy: 0.8425 - val_loss: 0.2641 - val_accuracy: 0.8833\n",
      "Epoch 281/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3296 - accuracy: 0.8433 - val_loss: 0.2562 - val_accuracy: 0.8883\n",
      "Epoch 282/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3281 - accuracy: 0.8442 - val_loss: 0.2559 - val_accuracy: 0.8879\n",
      "Epoch 283/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3253 - accuracy: 0.8462 - val_loss: 0.2599 - val_accuracy: 0.8852\n",
      "Epoch 284/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3260 - accuracy: 0.8457 - val_loss: 0.2531 - val_accuracy: 0.8890\n",
      "Epoch 285/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3253 - accuracy: 0.8457 - val_loss: 0.2562 - val_accuracy: 0.8866\n",
      "Epoch 286/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3299 - accuracy: 0.8439 - val_loss: 0.2520 - val_accuracy: 0.8902\n",
      "Epoch 287/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3255 - accuracy: 0.8458 - val_loss: 0.2728 - val_accuracy: 0.8793\n",
      "Epoch 288/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3243 - accuracy: 0.8471 - val_loss: 0.2503 - val_accuracy: 0.8883\n",
      "Epoch 289/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3253 - accuracy: 0.8461 - val_loss: 0.2583 - val_accuracy: 0.8878\n",
      "Epoch 290/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3272 - accuracy: 0.8450 - val_loss: 0.2514 - val_accuracy: 0.8905\n",
      "Epoch 291/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3267 - accuracy: 0.8452 - val_loss: 0.2505 - val_accuracy: 0.8901\n",
      "Epoch 292/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3186 - accuracy: 0.8503 - val_loss: 0.2436 - val_accuracy: 0.8937\n",
      "Epoch 293/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3196 - accuracy: 0.8493 - val_loss: 0.2476 - val_accuracy: 0.8909\n",
      "Epoch 294/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3254 - accuracy: 0.8461 - val_loss: 0.2526 - val_accuracy: 0.8901\n",
      "Epoch 295/300\n",
      "5416/5416 [==============================] - 95s 17ms/step - loss: 0.3251 - accuracy: 0.8466 - val_loss: 0.2599 - val_accuracy: 0.8867\n",
      "Epoch 296/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3253 - accuracy: 0.8467 - val_loss: 0.2584 - val_accuracy: 0.8868\n",
      "Epoch 297/300\n",
      "5416/5416 [==============================] - 95s 18ms/step - loss: 0.3251 - accuracy: 0.8463 - val_loss: 0.2534 - val_accuracy: 0.8896\n",
      "Epoch 298/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.3289 - accuracy: 0.8445 - val_loss: 0.2669 - val_accuracy: 0.8817\n",
      "Epoch 299/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.3231 - accuracy: 0.8474 - val_loss: 0.2538 - val_accuracy: 0.8892\n",
      "Epoch 300/300\n",
      "5416/5416 [==============================] - 94s 17ms/step - loss: 0.3242 - accuracy: 0.8477 - val_loss: 0.2562 - val_accuracy: 0.8877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000025E001A1370> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "core.retrain_model(model_base_id, kt_iter, db_ver, ROOT_PATH=ROOT_PATH, DB_ROOT_PATH=DB_ROOT_PATH, dataset_size=dataset_size, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, retrain_epochs=retrain_epochs, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071babf8-9b5d-4e64-b2e7-1238370eaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id='326'\n",
    "kt_iter='33'\n",
    "db_ver='8'\n",
    "ROOT_PATH = './'\n",
    "DB_ROOT_PATH = 'J:\\#PROJECT\\idx'\n",
    "dataset_size = 'full_new_wsd'\n",
    "batch_size = 64\n",
    "shuffle_buffer_size = 2048\n",
    "retrain_epochs = 150\n",
    "generator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce08fd5d-8563-449c-b9d7-cfc9e2b2f6b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 423\n",
      "Total constituents: 423\n",
      "Load model from keras_tuner\n",
      "Epoch 1/150\n",
      "13199/13199 [==============================] - 197s 14ms/step - loss: 0.6443 - accuracy: 0.6144 - val_loss: 0.6426 - val_accuracy: 0.6089\n",
      "Epoch 2/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6337 - accuracy: 0.6246 - val_loss: 0.6371 - val_accuracy: 0.6127\n",
      "Epoch 3/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6298 - accuracy: 0.6275 - val_loss: 0.6402 - val_accuracy: 0.6133\n",
      "Epoch 4/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6269 - accuracy: 0.6296 - val_loss: 0.6398 - val_accuracy: 0.6127\n",
      "Epoch 5/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6248 - accuracy: 0.6313 - val_loss: 0.6400 - val_accuracy: 0.6140\n",
      "Epoch 6/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6229 - accuracy: 0.6323 - val_loss: 0.6435 - val_accuracy: 0.6122\n",
      "Epoch 7/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6214 - accuracy: 0.6329 - val_loss: 0.6397 - val_accuracy: 0.6135\n",
      "Epoch 8/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6197 - accuracy: 0.6341 - val_loss: 0.6429 - val_accuracy: 0.6108\n",
      "Epoch 9/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6183 - accuracy: 0.6351 - val_loss: 0.6440 - val_accuracy: 0.6126\n",
      "Epoch 10/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6171 - accuracy: 0.6359 - val_loss: 0.6462 - val_accuracy: 0.6114\n",
      "Epoch 11/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6160 - accuracy: 0.6367 - val_loss: 0.6445 - val_accuracy: 0.6116\n",
      "Epoch 12/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6147 - accuracy: 0.6377 - val_loss: 0.6461 - val_accuracy: 0.6105\n",
      "Epoch 13/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6135 - accuracy: 0.6385 - val_loss: 0.6482 - val_accuracy: 0.6101\n",
      "Epoch 14/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6126 - accuracy: 0.6392 - val_loss: 0.6466 - val_accuracy: 0.6088\n",
      "Epoch 15/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6112 - accuracy: 0.6399 - val_loss: 0.6513 - val_accuracy: 0.6062\n",
      "Epoch 16/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6105 - accuracy: 0.6408 - val_loss: 0.6553 - val_accuracy: 0.6063\n",
      "Epoch 17/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6094 - accuracy: 0.6420 - val_loss: 0.6526 - val_accuracy: 0.6082\n",
      "Epoch 18/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6082 - accuracy: 0.6428 - val_loss: 0.6545 - val_accuracy: 0.6044\n",
      "Epoch 19/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6080 - accuracy: 0.6428 - val_loss: 0.6535 - val_accuracy: 0.6080\n",
      "Epoch 20/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6072 - accuracy: 0.6435 - val_loss: 0.6563 - val_accuracy: 0.6066\n",
      "Epoch 21/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6062 - accuracy: 0.6441 - val_loss: 0.6564 - val_accuracy: 0.6058\n",
      "Epoch 22/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6058 - accuracy: 0.6446 - val_loss: 0.6557 - val_accuracy: 0.6061\n",
      "Epoch 23/150\n",
      "13199/13199 [==============================] - 191s 15ms/step - loss: 0.6046 - accuracy: 0.6456 - val_loss: 0.6562 - val_accuracy: 0.6068\n",
      "Epoch 24/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6043 - accuracy: 0.6454 - val_loss: 0.6575 - val_accuracy: 0.6063\n",
      "Epoch 25/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6039 - accuracy: 0.6464 - val_loss: 0.6551 - val_accuracy: 0.6050\n",
      "Epoch 26/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6032 - accuracy: 0.6464 - val_loss: 0.6604 - val_accuracy: 0.6011\n",
      "Epoch 27/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6050 - accuracy: 0.6455 - val_loss: 0.6567 - val_accuracy: 0.6055\n",
      "Epoch 28/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6045 - accuracy: 0.6464 - val_loss: 0.6618 - val_accuracy: 0.6048\n",
      "Epoch 29/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6037 - accuracy: 0.6466 - val_loss: 0.6545 - val_accuracy: 0.6047\n",
      "Epoch 30/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6030 - accuracy: 0.6474 - val_loss: 0.6578 - val_accuracy: 0.6069\n",
      "Epoch 31/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6025 - accuracy: 0.6478 - val_loss: 0.6602 - val_accuracy: 0.6039\n",
      "Epoch 32/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6029 - accuracy: 0.6479 - val_loss: 0.6558 - val_accuracy: 0.6058\n",
      "Epoch 33/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6029 - accuracy: 0.6479 - val_loss: 0.6589 - val_accuracy: 0.6053\n",
      "Epoch 34/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6027 - accuracy: 0.6476 - val_loss: 0.6623 - val_accuracy: 0.6021\n",
      "Epoch 35/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6026 - accuracy: 0.6483 - val_loss: 0.6563 - val_accuracy: 0.6020\n",
      "Epoch 36/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6025 - accuracy: 0.6485 - val_loss: 0.6568 - val_accuracy: 0.6043\n",
      "Epoch 37/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6026 - accuracy: 0.6484 - val_loss: 0.6580 - val_accuracy: 0.6034\n",
      "Epoch 38/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6024 - accuracy: 0.6485 - val_loss: 0.6610 - val_accuracy: 0.6040\n",
      "Epoch 39/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6021 - accuracy: 0.6488 - val_loss: 0.6593 - val_accuracy: 0.6045\n",
      "Epoch 40/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6024 - accuracy: 0.6488 - val_loss: 0.6582 - val_accuracy: 0.6024\n",
      "Epoch 41/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6026 - accuracy: 0.6489 - val_loss: 0.6599 - val_accuracy: 0.6026\n",
      "Epoch 42/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6025 - accuracy: 0.6488 - val_loss: 0.6649 - val_accuracy: 0.6018\n",
      "Epoch 43/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6027 - accuracy: 0.6483 - val_loss: 0.6564 - val_accuracy: 0.6037\n",
      "Epoch 44/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6025 - accuracy: 0.6491 - val_loss: 0.6569 - val_accuracy: 0.6049\n",
      "Epoch 45/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6029 - accuracy: 0.6483 - val_loss: 0.6599 - val_accuracy: 0.6037\n",
      "Epoch 46/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6046 - accuracy: 0.6475 - val_loss: 0.6563 - val_accuracy: 0.6030\n",
      "Epoch 47/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6062 - accuracy: 0.6464 - val_loss: 0.6603 - val_accuracy: 0.6020\n",
      "Epoch 48/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6065 - accuracy: 0.6459 - val_loss: 0.6595 - val_accuracy: 0.6019\n",
      "Epoch 49/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6062 - accuracy: 0.6458 - val_loss: 0.6547 - val_accuracy: 0.6050\n",
      "Epoch 50/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6057 - accuracy: 0.6471 - val_loss: 0.6542 - val_accuracy: 0.6051\n",
      "Epoch 51/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6058 - accuracy: 0.6468 - val_loss: 0.6550 - val_accuracy: 0.6039\n",
      "Epoch 52/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6075 - accuracy: 0.6457 - val_loss: 0.6549 - val_accuracy: 0.6060\n",
      "Epoch 53/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6079 - accuracy: 0.6452 - val_loss: 0.6596 - val_accuracy: 0.6033\n",
      "Epoch 54/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6093 - accuracy: 0.6440 - val_loss: 0.6547 - val_accuracy: 0.6044\n",
      "Epoch 55/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6112 - accuracy: 0.6432 - val_loss: 0.6537 - val_accuracy: 0.6037\n",
      "Epoch 56/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6103 - accuracy: 0.6436 - val_loss: 0.6526 - val_accuracy: 0.6033\n",
      "Epoch 57/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6115 - accuracy: 0.6429 - val_loss: 0.6525 - val_accuracy: 0.6057\n",
      "Epoch 58/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6129 - accuracy: 0.6417 - val_loss: 0.6536 - val_accuracy: 0.6046\n",
      "Epoch 59/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6164 - accuracy: 0.6392 - val_loss: 0.6526 - val_accuracy: 0.6063\n",
      "Epoch 60/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6171 - accuracy: 0.6382 - val_loss: 0.6529 - val_accuracy: 0.6056\n",
      "Epoch 61/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6199 - accuracy: 0.6360 - val_loss: 0.6499 - val_accuracy: 0.6078\n",
      "Epoch 62/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6221 - accuracy: 0.6340 - val_loss: 0.6508 - val_accuracy: 0.6067\n",
      "Epoch 63/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6247 - accuracy: 0.6319 - val_loss: 0.6498 - val_accuracy: 0.6054\n",
      "Epoch 64/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6255 - accuracy: 0.6319 - val_loss: 0.6489 - val_accuracy: 0.6066\n",
      "Epoch 65/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6272 - accuracy: 0.6307 - val_loss: 0.6482 - val_accuracy: 0.6074\n",
      "Epoch 66/150\n",
      "13199/13199 [==============================] - 194s 15ms/step - loss: 0.6280 - accuracy: 0.6295 - val_loss: 0.6464 - val_accuracy: 0.6075\n",
      "Epoch 67/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6289 - accuracy: 0.6290 - val_loss: 0.6478 - val_accuracy: 0.6058\n",
      "Epoch 68/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6299 - accuracy: 0.6280 - val_loss: 0.6473 - val_accuracy: 0.6057\n",
      "Epoch 69/150\n",
      "13199/13199 [==============================] - 194s 15ms/step - loss: 0.6315 - accuracy: 0.6269 - val_loss: 0.6486 - val_accuracy: 0.6070\n",
      "Epoch 70/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6320 - accuracy: 0.6268 - val_loss: 0.6445 - val_accuracy: 0.6083\n",
      "Epoch 71/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6326 - accuracy: 0.6259 - val_loss: 0.6461 - val_accuracy: 0.6068\n",
      "Epoch 72/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6327 - accuracy: 0.6254 - val_loss: 0.6453 - val_accuracy: 0.6087\n",
      "Epoch 73/150\n",
      "13199/13199 [==============================] - 194s 15ms/step - loss: 0.6327 - accuracy: 0.6261 - val_loss: 0.6456 - val_accuracy: 0.6079\n",
      "Epoch 74/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6321 - accuracy: 0.6263 - val_loss: 0.6449 - val_accuracy: 0.6071\n",
      "Epoch 75/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6325 - accuracy: 0.6255 - val_loss: 0.6452 - val_accuracy: 0.6066\n",
      "Epoch 76/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6339 - accuracy: 0.6243 - val_loss: 0.6442 - val_accuracy: 0.6070\n",
      "Epoch 77/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6339 - accuracy: 0.6243 - val_loss: 0.6446 - val_accuracy: 0.6065\n",
      "Epoch 78/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6341 - accuracy: 0.6244 - val_loss: 0.6466 - val_accuracy: 0.6059\n",
      "Epoch 79/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6352 - accuracy: 0.6234 - val_loss: 0.6449 - val_accuracy: 0.6065\n",
      "Epoch 80/150\n",
      "13199/13199 [==============================] - 187s 14ms/step - loss: 0.6369 - accuracy: 0.6232 - val_loss: 0.6452 - val_accuracy: 0.6089\n",
      "Epoch 81/150\n",
      "13199/13199 [==============================] - 187s 14ms/step - loss: 0.6376 - accuracy: 0.6222 - val_loss: 0.6466 - val_accuracy: 0.6080\n",
      "Epoch 82/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6379 - accuracy: 0.6214 - val_loss: 0.6455 - val_accuracy: 0.6084\n",
      "Epoch 83/150\n",
      "13199/13199 [==============================] - 185s 14ms/step - loss: 0.6387 - accuracy: 0.6210 - val_loss: 0.6480 - val_accuracy: 0.6076\n",
      "Epoch 84/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6408 - accuracy: 0.6196 - val_loss: 0.6487 - val_accuracy: 0.6064\n",
      "Epoch 85/150\n",
      "13199/13199 [==============================] - 187s 14ms/step - loss: 0.6405 - accuracy: 0.6201 - val_loss: 0.6472 - val_accuracy: 0.6064\n",
      "Epoch 86/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6408 - accuracy: 0.6199 - val_loss: 0.6492 - val_accuracy: 0.6068\n",
      "Epoch 87/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6413 - accuracy: 0.6192 - val_loss: 0.6492 - val_accuracy: 0.6082\n",
      "Epoch 88/150\n",
      "13199/13199 [==============================] - 186s 14ms/step - loss: 0.6407 - accuracy: 0.6196 - val_loss: 0.6483 - val_accuracy: 0.6071\n",
      "Epoch 89/150\n",
      "13199/13199 [==============================] - 186s 14ms/step - loss: 0.6404 - accuracy: 0.6194 - val_loss: 0.6476 - val_accuracy: 0.6074\n",
      "Epoch 90/150\n",
      "13199/13199 [==============================] - 187s 14ms/step - loss: 0.6410 - accuracy: 0.6193 - val_loss: 0.6459 - val_accuracy: 0.6072\n",
      "Epoch 91/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6411 - accuracy: 0.6191 - val_loss: 0.6455 - val_accuracy: 0.6060\n",
      "Epoch 92/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6411 - accuracy: 0.6183 - val_loss: 0.6473 - val_accuracy: 0.6058\n",
      "Epoch 93/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6417 - accuracy: 0.6189 - val_loss: 0.6481 - val_accuracy: 0.6055\n",
      "Epoch 94/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6415 - accuracy: 0.6186 - val_loss: 0.6477 - val_accuracy: 0.6060\n",
      "Epoch 95/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6415 - accuracy: 0.6179 - val_loss: 0.6472 - val_accuracy: 0.6050\n",
      "Epoch 96/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6417 - accuracy: 0.6179 - val_loss: 0.6476 - val_accuracy: 0.6057\n",
      "Epoch 97/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6423 - accuracy: 0.6179 - val_loss: 0.6486 - val_accuracy: 0.6052\n",
      "Epoch 98/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6423 - accuracy: 0.6178 - val_loss: 0.6474 - val_accuracy: 0.6043\n",
      "Epoch 99/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6427 - accuracy: 0.6181 - val_loss: 0.6474 - val_accuracy: 0.6064\n",
      "Epoch 100/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6424 - accuracy: 0.6182 - val_loss: 0.6465 - val_accuracy: 0.6068\n",
      "Epoch 101/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6429 - accuracy: 0.6175 - val_loss: 0.6484 - val_accuracy: 0.6067\n",
      "Epoch 102/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6426 - accuracy: 0.6173 - val_loss: 0.6453 - val_accuracy: 0.6065\n",
      "Epoch 103/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6425 - accuracy: 0.6176 - val_loss: 0.6471 - val_accuracy: 0.6061\n",
      "Epoch 104/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6427 - accuracy: 0.6172 - val_loss: 0.6463 - val_accuracy: 0.6054\n",
      "Epoch 105/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6428 - accuracy: 0.6168 - val_loss: 0.6470 - val_accuracy: 0.6060\n",
      "Epoch 106/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6437 - accuracy: 0.6163 - val_loss: 0.6473 - val_accuracy: 0.6056\n",
      "Epoch 107/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6440 - accuracy: 0.6159 - val_loss: 0.6462 - val_accuracy: 0.6063\n",
      "Epoch 108/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6439 - accuracy: 0.6157 - val_loss: 0.6457 - val_accuracy: 0.6065\n",
      "Epoch 109/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6437 - accuracy: 0.6158 - val_loss: 0.6453 - val_accuracy: 0.6065\n",
      "Epoch 110/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6436 - accuracy: 0.6160 - val_loss: 0.6451 - val_accuracy: 0.6045\n",
      "Epoch 111/150\n",
      "13199/13199 [==============================] - 188s 14ms/step - loss: 0.6435 - accuracy: 0.6158 - val_loss: 0.6465 - val_accuracy: 0.6059\n",
      "Epoch 112/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6438 - accuracy: 0.6157 - val_loss: 0.6465 - val_accuracy: 0.6055\n",
      "Epoch 113/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6440 - accuracy: 0.6153 - val_loss: 0.6454 - val_accuracy: 0.6055\n",
      "Epoch 114/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6443 - accuracy: 0.6150 - val_loss: 0.6465 - val_accuracy: 0.6036\n",
      "Epoch 115/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6448 - accuracy: 0.6151 - val_loss: 0.6464 - val_accuracy: 0.6042\n",
      "Epoch 116/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6447 - accuracy: 0.6150 - val_loss: 0.6466 - val_accuracy: 0.6052\n",
      "Epoch 117/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6447 - accuracy: 0.6150 - val_loss: 0.6466 - val_accuracy: 0.6044\n",
      "Epoch 118/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6451 - accuracy: 0.6151 - val_loss: 0.6480 - val_accuracy: 0.6034\n",
      "Epoch 119/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6451 - accuracy: 0.6153 - val_loss: 0.6487 - val_accuracy: 0.6018\n",
      "Epoch 120/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6452 - accuracy: 0.6155 - val_loss: 0.6482 - val_accuracy: 0.6028\n",
      "Epoch 121/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6451 - accuracy: 0.6158 - val_loss: 0.6492 - val_accuracy: 0.6015\n",
      "Epoch 122/150\n",
      "13199/13199 [==============================] - 190s 14ms/step - loss: 0.6443 - accuracy: 0.6160 - val_loss: 0.6487 - val_accuracy: 0.6021\n",
      "Epoch 123/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6443 - accuracy: 0.6157 - val_loss: 0.6485 - val_accuracy: 0.6016\n",
      "Epoch 124/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6447 - accuracy: 0.6155 - val_loss: 0.6481 - val_accuracy: 0.6029\n",
      "Epoch 125/150\n",
      "13199/13199 [==============================] - 189s 14ms/step - loss: 0.6448 - accuracy: 0.6150 - val_loss: 0.6473 - val_accuracy: 0.6025\n",
      "Epoch 126/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6452 - accuracy: 0.6152 - val_loss: 0.6472 - val_accuracy: 0.6040\n",
      "Epoch 127/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6452 - accuracy: 0.6151 - val_loss: 0.6485 - val_accuracy: 0.6025\n",
      "Epoch 128/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6451 - accuracy: 0.6151 - val_loss: 0.6468 - val_accuracy: 0.6045\n",
      "Epoch 129/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6451 - accuracy: 0.6143 - val_loss: 0.6478 - val_accuracy: 0.6022\n",
      "Epoch 130/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6452 - accuracy: 0.6147 - val_loss: 0.6479 - val_accuracy: 0.6031\n",
      "Epoch 131/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6453 - accuracy: 0.6150 - val_loss: 0.6489 - val_accuracy: 0.6004\n",
      "Epoch 132/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6458 - accuracy: 0.6143 - val_loss: 0.6508 - val_accuracy: 0.6021\n",
      "Epoch 133/150\n",
      "13199/13199 [==============================] - 191s 14ms/step - loss: 0.6460 - accuracy: 0.6149 - val_loss: 0.6491 - val_accuracy: 0.6027\n",
      "Epoch 134/150\n",
      "13199/13199 [==============================] - 191s 15ms/step - loss: 0.6455 - accuracy: 0.6149 - val_loss: 0.6482 - val_accuracy: 0.6021\n",
      "Epoch 135/150\n",
      "13199/13199 [==============================] - 192s 15ms/step - loss: 0.6456 - accuracy: 0.6147 - val_loss: 0.6484 - val_accuracy: 0.6029\n",
      "Epoch 136/150\n",
      "13199/13199 [==============================] - 195s 15ms/step - loss: 0.6457 - accuracy: 0.6144 - val_loss: 0.6480 - val_accuracy: 0.6022\n",
      "Epoch 137/150\n",
      "13199/13199 [==============================] - 193s 15ms/step - loss: 0.6456 - accuracy: 0.6143 - val_loss: 0.6483 - val_accuracy: 0.6019\n",
      "Epoch 138/150\n",
      "13199/13199 [==============================] - 194s 15ms/step - loss: 0.6455 - accuracy: 0.6144 - val_loss: 0.6469 - val_accuracy: 0.6017\n",
      "Epoch 139/150\n",
      "13199/13199 [==============================] - 200s 15ms/step - loss: 0.6455 - accuracy: 0.6146 - val_loss: 0.6473 - val_accuracy: 0.6026\n",
      "Epoch 140/150\n",
      "13199/13199 [==============================] - 201s 15ms/step - loss: 0.6458 - accuracy: 0.6140 - val_loss: 0.6477 - val_accuracy: 0.6011\n",
      "Epoch 141/150\n",
      "13199/13199 [==============================] - 200s 15ms/step - loss: 0.6456 - accuracy: 0.6144 - val_loss: 0.6482 - val_accuracy: 0.6019\n",
      "Epoch 142/150\n",
      "13199/13199 [==============================] - 200s 15ms/step - loss: 0.6463 - accuracy: 0.6142 - val_loss: 0.6488 - val_accuracy: 0.6018\n",
      "Epoch 143/150\n",
      "13199/13199 [==============================] - 200s 15ms/step - loss: 0.6468 - accuracy: 0.6133 - val_loss: 0.6494 - val_accuracy: 0.6004\n",
      "Epoch 144/150\n",
      "13199/13199 [==============================] - 197s 15ms/step - loss: 0.6464 - accuracy: 0.6139 - val_loss: 0.6483 - val_accuracy: 0.6034\n",
      "Epoch 145/150\n",
      "13199/13199 [==============================] - 197s 15ms/step - loss: 0.6466 - accuracy: 0.6135 - val_loss: 0.6490 - val_accuracy: 0.6032\n",
      "Epoch 146/150\n",
      "13199/13199 [==============================] - 196s 15ms/step - loss: 0.6471 - accuracy: 0.6132 - val_loss: 0.6491 - val_accuracy: 0.6024\n",
      "Epoch 147/150\n",
      "13199/13199 [==============================] - 195s 15ms/step - loss: 0.6466 - accuracy: 0.6140 - val_loss: 0.6489 - val_accuracy: 0.6025\n",
      "Epoch 148/150\n",
      "13199/13199 [==============================] - 200s 15ms/step - loss: 0.6463 - accuracy: 0.6142 - val_loss: 0.6487 - val_accuracy: 0.6031\n",
      "Epoch 149/150\n",
      "13199/13199 [==============================] - 199s 15ms/step - loss: 0.6464 - accuracy: 0.6139 - val_loss: 0.6506 - val_accuracy: 0.6016\n",
      "Epoch 150/150\n",
      "13199/13199 [==============================] - 195s 15ms/step - loss: 0.6470 - accuracy: 0.6137 - val_loss: 0.6506 - val_accuracy: 0.6034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002B000001CD0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "core.retrain_model(model_base_id, kt_iter, db_ver, ROOT_PATH=ROOT_PATH, DB_ROOT_PATH=DB_ROOT_PATH, dataset_size=dataset_size, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, retrain_epochs=retrain_epochs, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b577319f-bb38-4f4f-891c-345766375f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id='326'\n",
    "kt_iter='33.old (mix)'\n",
    "db_ver='8'\n",
    "ROOT_PATH = './'\n",
    "DB_ROOT_PATH = 'J:\\#PROJECT\\idx'\n",
    "dataset_size = 'full_new_wsd_mix1'\n",
    "batch_size = 64\n",
    "shuffle_buffer_size = 2048\n",
    "retrain_epochs = 50\n",
    "generator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f12f898-82c1-473d-93e0-ebf7604b8e6a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 704\n",
      "Total constituents: 423\n",
      "Load model from keras_tuner\n",
      "Epoch 1/50\n",
      "15498/15498 [==============================] - 231s 14ms/step - loss: 0.6468 - accuracy: 0.6132 - val_loss: 0.6396 - val_accuracy: 0.6125\n",
      "Epoch 2/50\n",
      "15498/15498 [==============================] - 222s 14ms/step - loss: 0.6401 - accuracy: 0.6201 - val_loss: 0.6396 - val_accuracy: 0.6129\n",
      "Epoch 3/50\n",
      "15498/15498 [==============================] - 223s 14ms/step - loss: 0.6368 - accuracy: 0.6225 - val_loss: 0.6406 - val_accuracy: 0.6147\n",
      "Epoch 4/50\n",
      "15498/15498 [==============================] - 221s 14ms/step - loss: 0.6340 - accuracy: 0.6251 - val_loss: 0.6381 - val_accuracy: 0.6150\n",
      "Epoch 5/50\n",
      "15498/15498 [==============================] - 220s 14ms/step - loss: 0.6325 - accuracy: 0.6257 - val_loss: 0.6378 - val_accuracy: 0.6161\n",
      "Epoch 6/50\n",
      "15498/15498 [==============================] - 220s 14ms/step - loss: 0.6315 - accuracy: 0.6264 - val_loss: 0.6377 - val_accuracy: 0.6157\n",
      "Epoch 7/50\n",
      "15498/15498 [==============================] - 221s 14ms/step - loss: 0.6303 - accuracy: 0.6271 - val_loss: 0.6377 - val_accuracy: 0.6162\n",
      "Epoch 8/50\n",
      "15498/15498 [==============================] - 221s 14ms/step - loss: 0.6292 - accuracy: 0.6278 - val_loss: 0.6390 - val_accuracy: 0.6158\n",
      "Epoch 9/50\n",
      "15498/15498 [==============================] - 224s 14ms/step - loss: 0.6282 - accuracy: 0.6284 - val_loss: 0.6389 - val_accuracy: 0.6165\n",
      "Epoch 10/50\n",
      "15498/15498 [==============================] - 224s 14ms/step - loss: 0.6280 - accuracy: 0.6284 - val_loss: 0.6401 - val_accuracy: 0.6151\n",
      "Epoch 11/50\n",
      "15498/15498 [==============================] - 224s 14ms/step - loss: 0.6273 - accuracy: 0.6288 - val_loss: 0.6386 - val_accuracy: 0.6153\n",
      "Epoch 12/50\n",
      "15498/15498 [==============================] - 222s 14ms/step - loss: 0.6266 - accuracy: 0.6294 - val_loss: 0.6397 - val_accuracy: 0.6154\n",
      "Epoch 13/50\n",
      "15498/15498 [==============================] - 223s 14ms/step - loss: 0.6260 - accuracy: 0.6294 - val_loss: 0.6443 - val_accuracy: 0.6151\n",
      "Epoch 14/50\n",
      "15498/15498 [==============================] - 220s 14ms/step - loss: 0.6257 - accuracy: 0.6296 - val_loss: 0.6394 - val_accuracy: 0.6154\n",
      "Epoch 15/50\n",
      "15498/15498 [==============================] - 223s 14ms/step - loss: 0.6258 - accuracy: 0.6292 - val_loss: 0.6393 - val_accuracy: 0.6156\n",
      "Epoch 16/50\n",
      "15498/15498 [==============================] - 221s 14ms/step - loss: 0.6251 - accuracy: 0.6300 - val_loss: 0.6410 - val_accuracy: 0.6143\n",
      "Epoch 17/50\n",
      "15498/15498 [==============================] - 219s 14ms/step - loss: 0.6247 - accuracy: 0.6303 - val_loss: 0.6432 - val_accuracy: 0.6125\n",
      "Epoch 18/50\n",
      "15498/15498 [==============================] - 217s 14ms/step - loss: 0.6246 - accuracy: 0.6303 - val_loss: 0.6429 - val_accuracy: 0.6144\n",
      "Epoch 19/50\n",
      "15498/15498 [==============================] - 222s 14ms/step - loss: 0.6246 - accuracy: 0.6304 - val_loss: 0.6413 - val_accuracy: 0.6111\n",
      "Epoch 20/50\n",
      "15498/15498 [==============================] - 225s 14ms/step - loss: 0.6241 - accuracy: 0.6303 - val_loss: 0.6414 - val_accuracy: 0.6136\n",
      "Epoch 21/50\n",
      "15498/15498 [==============================] - 224s 14ms/step - loss: 0.6241 - accuracy: 0.6307 - val_loss: 0.6417 - val_accuracy: 0.6141\n",
      "Epoch 22/50\n",
      "15498/15498 [==============================] - 222s 14ms/step - loss: 0.6242 - accuracy: 0.6308 - val_loss: 0.6405 - val_accuracy: 0.6136\n",
      "Epoch 23/50\n",
      "15498/15498 [==============================] - 224s 14ms/step - loss: 0.6240 - accuracy: 0.6305 - val_loss: 0.6443 - val_accuracy: 0.6124\n",
      "Epoch 24/50\n",
      "15498/15498 [==============================] - 223s 14ms/step - loss: 0.6237 - accuracy: 0.6307 - val_loss: 0.6403 - val_accuracy: 0.6142\n",
      "Epoch 25/50\n",
      "15498/15498 [==============================] - 224s 14ms/step - loss: 0.6233 - accuracy: 0.6309 - val_loss: 0.6436 - val_accuracy: 0.6124\n",
      "Epoch 26/50\n",
      "15498/15498 [==============================] - 223s 14ms/step - loss: 0.6233 - accuracy: 0.6311 - val_loss: 0.6407 - val_accuracy: 0.6137\n",
      "Epoch 27/50\n",
      "15498/15498 [==============================] - 221s 14ms/step - loss: 0.6237 - accuracy: 0.6307 - val_loss: 0.6416 - val_accuracy: 0.6134\n",
      "Epoch 28/50\n",
      "15498/15498 [==============================] - 224s 14ms/step - loss: 0.6242 - accuracy: 0.6306 - val_loss: 0.6409 - val_accuracy: 0.6136\n",
      "Epoch 29/50\n",
      "15498/15498 [==============================] - 224s 14ms/step - loss: 0.6238 - accuracy: 0.6310 - val_loss: 0.6448 - val_accuracy: 0.6124\n",
      "Epoch 30/50\n",
      "15498/15498 [==============================] - 225s 15ms/step - loss: 0.6232 - accuracy: 0.6314 - val_loss: 0.6439 - val_accuracy: 0.6102\n",
      "Epoch 31/50\n",
      "15498/15498 [==============================] - 226s 15ms/step - loss: 0.6239 - accuracy: 0.6310 - val_loss: 0.6432 - val_accuracy: 0.6107\n",
      "Epoch 32/50\n",
      "15498/15498 [==============================] - 226s 15ms/step - loss: 0.6243 - accuracy: 0.6309 - val_loss: 0.6433 - val_accuracy: 0.6117\n",
      "Epoch 33/50\n",
      "15498/15498 [==============================] - 227s 15ms/step - loss: 0.6245 - accuracy: 0.6306 - val_loss: 0.6440 - val_accuracy: 0.6119\n",
      "Epoch 34/50\n",
      "15498/15498 [==============================] - 227s 15ms/step - loss: 0.6243 - accuracy: 0.6313 - val_loss: 0.6478 - val_accuracy: 0.6107\n",
      "Epoch 35/50\n",
      "15498/15498 [==============================] - 225s 15ms/step - loss: 0.6245 - accuracy: 0.6309 - val_loss: 0.6435 - val_accuracy: 0.6112\n",
      "Epoch 36/50\n",
      "15498/15498 [==============================] - 226s 15ms/step - loss: 0.6256 - accuracy: 0.6304 - val_loss: 0.6416 - val_accuracy: 0.6126\n",
      "Epoch 37/50\n",
      "15498/15498 [==============================] - 225s 15ms/step - loss: 0.6256 - accuracy: 0.6304 - val_loss: 0.6438 - val_accuracy: 0.6122\n",
      "Epoch 38/50\n",
      "15498/15498 [==============================] - 223s 14ms/step - loss: 0.6259 - accuracy: 0.6300 - val_loss: 0.6444 - val_accuracy: 0.6121\n",
      "Epoch 39/50\n",
      "15498/15498 [==============================] - 222s 14ms/step - loss: 0.6261 - accuracy: 0.6299 - val_loss: 0.6453 - val_accuracy: 0.6112\n",
      "Epoch 40/50\n",
      "15498/15498 [==============================] - 223s 14ms/step - loss: 0.6267 - accuracy: 0.6294 - val_loss: 0.6436 - val_accuracy: 0.6112\n",
      "Epoch 41/50\n",
      "15498/15498 [==============================] - 223s 14ms/step - loss: 0.6289 - accuracy: 0.6276 - val_loss: 0.6453 - val_accuracy: 0.6106\n",
      "Epoch 42/50\n",
      "15498/15498 [==============================] - 222s 14ms/step - loss: 0.6299 - accuracy: 0.6274 - val_loss: 0.6448 - val_accuracy: 0.6124\n",
      "Epoch 43/50\n",
      "15498/15498 [==============================] - 222s 14ms/step - loss: 0.6296 - accuracy: 0.6278 - val_loss: 0.6431 - val_accuracy: 0.6131\n",
      "Epoch 44/50\n",
      "15498/15498 [==============================] - 223s 14ms/step - loss: 0.6299 - accuracy: 0.6276 - val_loss: 0.6401 - val_accuracy: 0.6134\n",
      "Epoch 45/50\n",
      "15498/15498 [==============================] - 222s 14ms/step - loss: 0.6306 - accuracy: 0.6266 - val_loss: 0.6413 - val_accuracy: 0.6138\n",
      "Epoch 46/50\n",
      "15498/15498 [==============================] - 226s 15ms/step - loss: 0.6321 - accuracy: 0.6264 - val_loss: 0.6408 - val_accuracy: 0.6125\n",
      "Epoch 47/50\n",
      "15498/15498 [==============================] - 225s 14ms/step - loss: 0.6334 - accuracy: 0.6253 - val_loss: 0.6427 - val_accuracy: 0.6119\n",
      "Epoch 48/50\n",
      "15498/15498 [==============================] - 221s 14ms/step - loss: 0.6361 - accuracy: 0.6241 - val_loss: 0.6445 - val_accuracy: 0.6108\n",
      "Epoch 49/50\n",
      "15498/15498 [==============================] - 221s 14ms/step - loss: 0.6372 - accuracy: 0.6227 - val_loss: 0.6422 - val_accuracy: 0.6111\n",
      "Epoch 50/50\n",
      "15498/15498 [==============================] - 221s 14ms/step - loss: 0.6377 - accuracy: 0.6226 - val_loss: 0.6423 - val_accuracy: 0.6109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002052FD571F0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "core.retrain_model(model_base_id, kt_iter, db_ver, ROOT_PATH=ROOT_PATH, DB_ROOT_PATH=DB_ROOT_PATH, dataset_size=dataset_size, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, retrain_epochs=retrain_epochs, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59d33f9-1170-4cfd-bbff-5988a90b5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id='326'\n",
    "kt_iter='33.old (mix)'\n",
    "db_ver='8'\n",
    "ROOT_PATH = './'\n",
    "DB_ROOT_PATH = 'J:\\#PROJECT\\idx'\n",
    "dataset_size = 'full_new_wsd_mix2'\n",
    "batch_size = 64\n",
    "shuffle_buffer_size = 2048\n",
    "retrain_epochs = 25\n",
    "generator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587fda6b-3390-41c9-9538-3d1170ecec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 1003\n",
      "Total constituents: 423\n",
      "Load model from keras_tuner\n",
      "Epoch 1/25\n",
      "18140/18140 [==============================] - 254s 14ms/step - loss: 0.6488 - accuracy: 0.6115 - val_loss: 0.6398 - val_accuracy: 0.6123\n",
      "Epoch 2/25\n",
      "18140/18140 [==============================] - 243s 13ms/step - loss: 0.6409 - accuracy: 0.6190 - val_loss: 0.6377 - val_accuracy: 0.6148\n",
      "Epoch 3/25\n",
      "18140/18140 [==============================] - 240s 13ms/step - loss: 0.6386 - accuracy: 0.6210 - val_loss: 0.6373 - val_accuracy: 0.6169\n",
      "Epoch 4/25\n",
      "18140/18140 [==============================] - 240s 13ms/step - loss: 0.6366 - accuracy: 0.6228 - val_loss: 0.6398 - val_accuracy: 0.6142\n",
      "Epoch 5/25\n",
      "18140/18140 [==============================] - 240s 13ms/step - loss: 0.6352 - accuracy: 0.6236 - val_loss: 0.6367 - val_accuracy: 0.6155\n",
      "Epoch 6/25\n",
      "18140/18140 [==============================] - 246s 14ms/step - loss: 0.6341 - accuracy: 0.6246 - val_loss: 0.6372 - val_accuracy: 0.6161\n",
      "Epoch 7/25\n",
      "18140/18140 [==============================] - 245s 13ms/step - loss: 0.6331 - accuracy: 0.6250 - val_loss: 0.6377 - val_accuracy: 0.6153\n",
      "Epoch 8/25\n",
      "18140/18140 [==============================] - 244s 13ms/step - loss: 0.6322 - accuracy: 0.6253 - val_loss: 0.6396 - val_accuracy: 0.6140\n",
      "Epoch 9/25\n",
      "18140/18140 [==============================] - 245s 13ms/step - loss: 0.6316 - accuracy: 0.6259 - val_loss: 0.6402 - val_accuracy: 0.6132\n",
      "Epoch 10/25\n",
      "18140/18140 [==============================] - 246s 14ms/step - loss: 0.6312 - accuracy: 0.6259 - val_loss: 0.6398 - val_accuracy: 0.6137\n",
      "Epoch 11/25\n",
      "18140/18140 [==============================] - 245s 14ms/step - loss: 0.6305 - accuracy: 0.6265 - val_loss: 0.6385 - val_accuracy: 0.6140\n",
      "Epoch 12/25\n",
      "18140/18140 [==============================] - 246s 14ms/step - loss: 0.6300 - accuracy: 0.6271 - val_loss: 0.6384 - val_accuracy: 0.6141\n",
      "Epoch 13/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6296 - accuracy: 0.6270 - val_loss: 0.6413 - val_accuracy: 0.6138\n",
      "Epoch 14/25\n",
      "18140/18140 [==============================] - 248s 14ms/step - loss: 0.6292 - accuracy: 0.6275 - val_loss: 0.6411 - val_accuracy: 0.6131\n",
      "Epoch 15/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6287 - accuracy: 0.6276 - val_loss: 0.6420 - val_accuracy: 0.6130\n",
      "Epoch 16/25\n",
      "18140/18140 [==============================] - 248s 14ms/step - loss: 0.6283 - accuracy: 0.6278 - val_loss: 0.6432 - val_accuracy: 0.6126\n",
      "Epoch 17/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6283 - accuracy: 0.6279 - val_loss: 0.6424 - val_accuracy: 0.6124\n",
      "Epoch 18/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6279 - accuracy: 0.6283 - val_loss: 0.6438 - val_accuracy: 0.6128\n",
      "Epoch 19/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6278 - accuracy: 0.6284 - val_loss: 0.6402 - val_accuracy: 0.6127\n",
      "Epoch 20/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6277 - accuracy: 0.6283 - val_loss: 0.6417 - val_accuracy: 0.6127\n",
      "Epoch 21/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6277 - accuracy: 0.6281 - val_loss: 0.6452 - val_accuracy: 0.6120\n",
      "Epoch 22/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6276 - accuracy: 0.6281 - val_loss: 0.6418 - val_accuracy: 0.6114\n",
      "Epoch 23/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6271 - accuracy: 0.6288 - val_loss: 0.6451 - val_accuracy: 0.6110\n",
      "Epoch 24/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6273 - accuracy: 0.6286 - val_loss: 0.6418 - val_accuracy: 0.6111\n",
      "Epoch 25/25\n",
      "18140/18140 [==============================] - 247s 14ms/step - loss: 0.6279 - accuracy: 0.6282 - val_loss: 0.6435 - val_accuracy: 0.6123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DD1D4ACF10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "core.retrain_model(model_base_id, kt_iter, db_ver, ROOT_PATH=ROOT_PATH, DB_ROOT_PATH=DB_ROOT_PATH, dataset_size=dataset_size, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, retrain_epochs=retrain_epochs, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2790e3-5675-4ad8-8941-093ce94de09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd216697-7174-4dc6-9f7e-8be46326078e",
   "metadata": {},
   "source": [
    "### Manually retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e82ef471-b79f-41e0-ad45-9d9fa9da5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '3'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.025\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.5\n",
    "epochs = 5\n",
    "iter_id = f'model-{model_no}-{version}_constituent_limits-{constituent_limits}_id_constituent-{id_constituent}_min_vid_constituents-{min_vid_constituents}_epochs-{epochs}'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa39f962-1ee3-434e-81e9-d38548dd648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 1149\n",
      "Total constituents: 422\n",
      "Epoch 1/5\n",
      "9758/9758 [==============================] - 1481s 151ms/step - loss: 0.6713 - accuracy: 0.5938 - val_loss: 0.6662 - val_accuracy: 0.5976\n",
      "Epoch 2/5\n",
      "9758/9758 [==============================] - 1639s 168ms/step - loss: 0.6551 - accuracy: 0.6131 - val_loss: 0.6765 - val_accuracy: 0.5979\n",
      "Epoch 3/5\n",
      "9758/9758 [==============================] - 1890s 194ms/step - loss: 0.6411 - accuracy: 0.6266 - val_loss: 0.7078 - val_accuracy: 0.5837\n",
      "Epoch 4/5\n",
      "9758/9758 [==============================] - 1682s 172ms/step - loss: 0.6250 - accuracy: 0.6415 - val_loss: 0.7718 - val_accuracy: 0.5669\n",
      "Epoch 5/5\n",
      "9758/9758 [==============================] - 1446s 148ms/step - loss: 0.6099 - accuracy: 0.6553 - val_loss: 0.7890 - val_accuracy: 0.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000025FD82DF8B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000025FD8B43D60> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "history.history['batch_size'] = batch_size\n",
    "history.history['shuffle_buffer_size'] = shuffle_buffer_size\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c642afcb-a196-4e58-9c3c-436ed025c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '3'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.05\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.2\n",
    "epochs = 10\n",
    "batch_size = 512\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bed0edd-feaa-482a-87da-5c61ce2bd653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 1894\n",
      "Total constituents: 422\n",
      "Epoch 1/10\n",
      "3303/3303 [==============================] - 1798s 542ms/step - loss: 0.6764 - accuracy: 0.5841 - val_loss: 0.6627 - val_accuracy: 0.6036\n",
      "Epoch 2/10\n",
      "3303/3303 [==============================] - 1749s 529ms/step - loss: 0.6589 - accuracy: 0.6050 - val_loss: 0.6586 - val_accuracy: 0.6057\n",
      "Epoch 3/10\n",
      "3303/3303 [==============================] - 1684s 509ms/step - loss: 0.6552 - accuracy: 0.6103 - val_loss: 0.6603 - val_accuracy: 0.6060\n",
      "Epoch 4/10\n",
      "3303/3303 [==============================] - 1592s 482ms/step - loss: 0.6518 - accuracy: 0.6139 - val_loss: 0.6610 - val_accuracy: 0.6065\n",
      "Epoch 5/10\n",
      "3303/3303 [==============================] - 1744s 528ms/step - loss: 0.6484 - accuracy: 0.6171 - val_loss: 0.6693 - val_accuracy: 0.5900\n",
      "Epoch 6/10\n",
      "3303/3303 [==============================] - 1889s 571ms/step - loss: 0.6449 - accuracy: 0.6204 - val_loss: 0.6781 - val_accuracy: 0.5810\n",
      "Epoch 7/10\n",
      "3303/3303 [==============================] - 1845s 558ms/step - loss: 0.6410 - accuracy: 0.6241 - val_loss: 0.6937 - val_accuracy: 0.5739\n",
      "Epoch 8/10\n",
      "3303/3303 [==============================] - 1870s 566ms/step - loss: 0.6369 - accuracy: 0.6284 - val_loss: 0.7083 - val_accuracy: 0.5709\n",
      "Epoch 9/10\n",
      "3303/3303 [==============================] - 1905s 576ms/step - loss: 0.6328 - accuracy: 0.6324 - val_loss: 0.7226 - val_accuracy: 0.5681\n",
      "Epoch 10/10\n",
      "3303/3303 [==============================] - 1829s 553ms/step - loss: 0.6286 - accuracy: 0.6369 - val_loss: 0.7385 - val_accuracy: 0.5617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001BA45C6F040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001BA75F89CD0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no, min_vid_constituents=min_vid_constituents)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3260f020-94f3-4c15-a58c-3fd62ac36c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_id = '327'\n",
    "version = '5'\n",
    "model_no = model_base_id\n",
    "constituent_limits = 0.3\n",
    "id_constituent = 1\n",
    "min_vid_constituents = 0.2\n",
    "epochs = 5\n",
    "batch_size = 1024\n",
    "iter_id = f'model-{model_no}-{version}_constituentlimits-{constituent_limits}_idconstituent-{id_constituent}_minvidconstituents-{min_vid_constituents}_epochs-{epochs}_batchsize-{batch_size}_2'\n",
    "ROOT_PATH='./'\n",
    "DB_ROOT_PATH='J:\\#PROJECT\\idx'\n",
    "db_ver = '8'\n",
    "\n",
    "shuffle_buffer_size = 1\n",
    "generator=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4e389-a484-40f3-81d6-e55a1248c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total constituents: 10792\n",
      "Total constituents: 422\n",
      "Epoch 1-1/5\n",
      "2545/2545 [==============================] - 1506s 589ms/step - loss: 0.7689 - accuracy: 0.5178\n",
      "Epoch 1-2/5\n",
      "2588/2588 [==============================] - 1522s 588ms/step - loss: 0.7040 - accuracy: 0.5372\n",
      "Epoch 1-3/5\n",
      "2493/2493 [==============================] - 1440s 577ms/step - loss: 0.6892 - accuracy: 0.5520\n",
      "Epoch 1-4/5\n",
      "2478/2478 [==============================] - 1432s 578ms/step - loss: 0.6815 - accuracy: 0.5649\n",
      "Epoch 1-5/5\n",
      "2455/2455 [==============================] - 1433s 583ms/step - loss: 0.6751 - accuracy: 0.5766\n",
      "Epoch 1-6/5\n",
      "2551/2551 [==============================] - 1507s 590ms/step - loss: 0.6714 - accuracy: 0.5835\n",
      "Epoch 1-7/5\n",
      "2481/2481 [==============================] - 1466s 591ms/step - loss: 0.6674 - accuracy: 0.5903\n",
      "Epoch 1-8/5\n",
      "2531/2531 [==============================] - 1499s 592ms/step - loss: 0.6657 - accuracy: 0.5929\n",
      "Epoch 1-9/5\n",
      "2550/2550 [==============================] - 1524s 597ms/step - loss: 0.6637 - accuracy: 0.5968\n",
      "Epoch 1-10/5\n",
      "   1008/Unknown - 717s 711ms/step - loss: 0.6631 - accuracy: 0.5976"
     ]
    }
   ],
   "source": [
    "# Train: `slice_from_beginning`=True\n",
    "train_gen = core.load_dataset_wsd(slice_from_beginning=True, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=constituent_limits, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "# Validation: `slice_from_beginning`=False. constituent_limits in validation is always 0 (focus on idx performance progression only)\n",
    "validation_gen = core.load_dataset_wsd(slice_from_beginning=False, ROOT_PATH=DB_ROOT_PATH, db_ver=db_ver, constituent_limits=0, id_constituent=id_constituent, batch_size=batch_size, shuffle_buffer_size=shuffle_buffer_size, seed=0, generator=generator, model_no=model_no)\n",
    "\n",
    "# Load model backbone\n",
    "model = core.model_switcher_preloaded(model_no, version=version)\n",
    "if type(train_gen) == list:\n",
    "    for epoch in range(epochs):\n",
    "        for i, tg in enumerate(train_gen):\n",
    "            print(f'Epoch {epoch+1}-{i+1}/{epochs}')\n",
    "            if i < (len(train_gen) - 1):\n",
    "                history = model.fit(tg, epochs=1, verbose=1)\n",
    "            elif i == (len(train_gen) - 1):\n",
    "                history = model.fit(tg, validation_data=validation_gen, epochs=1, verbose=1)\n",
    "elif type(train_gen) != list:\n",
    "    history = model.fit(train_gen, validation_data=validation_gen, epochs=epochs, verbose=1)\n",
    "\n",
    "save_path = core.os.path.join(ROOT_PATH, f'models/preloaded/{iter_id}/')\n",
    "model.save_weights(f'{save_path}/weights/checkpoint')\n",
    "model.save(f'{save_path}/model')\n",
    "\n",
    "with open(f'{save_path}/history.json', 'w') as f:\n",
    "    core.json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202b4c3-7759-4eeb-95b4-3d8938fb85cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
